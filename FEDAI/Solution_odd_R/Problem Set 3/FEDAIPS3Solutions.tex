% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM SET LATEX TEMPLATE FILE
% DEFINE DOCUMENT STYLE, LOAD PACKAGES
\documentclass[11pt,notitlepage]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}    % ADD COMMENTS USING A PERCENT SIGN
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath, booktabs}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{subfig}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multicol}
\usepackage{multirow}
\setlength{\parindent}{0in}		% uncomment to remove indent at start of paragraphs
\usepackage{pdflscape}
\usepackage[english]{babel}
\usepackage[pdftex]{hyperref}
\usepackage{natbib}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphics}
\usepackage{multirow}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{latexsym}
\usepackage{rotating}
\usepackage{setspace}
\usepackage{layouts} 
\usepackage[titletoc]{appendix}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage[margin=1in]{geometry}
\usepackage{enumerate}
\usepackage{float}

\usepackage{xcolor}
\usepackage[printwatermark]{xwatermark}



\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
% FONTS
\usepackage[T1]{fontenc}					% always use this no matter what

% uncomment any one of these to see what it does to your font!
%\usepackage{pxfonts}
%\usepackage{cmbright}
%\usepackage{txfonts}
%\usepackage[adobe-utopia]{mathdesign}
%\usepackage{kpfonts}
%\usepackage{lmodern}
%\usepackage{newtxtext,newtxmath}



\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\title{Field Experiments: Design, Analysis and Interpretation \\
Solutions for Chapter 3 Exercises}
\author{Alan S. Gerber and Donald P. Green\footnote{Solutions prepared by Peter M. Aronow and revised by Alexander Coppock}}
\date{\today}
\maketitle

\section*{Question 1}
Important concepts: [10 points]
\begin{enumerate}[a)]
\item What is a standard error?  What is the difference between a standard error and a standard deviation?\\
Answer:\\
The standard error is a measure of the statistical uncertainty surrounding a parameter estimate. The standard error is a measure of dispersion in a sampling distribution; the standard deviation is the measure of dispersion of any distribution but is most often used to describe the dispersion in an observed variable. The standard error is the standard deviation of the sampling distribution, or the set of estimates that could have arisen under all possible random assignments. 
\item How is randomization inference used to test the sharp null hypothesis of no effect for any subject? 
Answer:\\ 
The sharp null hypothesis of no effect is a case in which $Y_i (1)= Y_i (0)$; under this assumption, all potential outcomes are observed because treated and untreated potential outcomes are identical.  In order to form the sampling distribution under the sharp null hypothesis of no effect, we simulate a random assignment and calculate the test statistic (for example, the difference-in-means between the assigned treatment and control groups). This simulation is repeated a large number of times in order to form the sampling distribution under the null hypothesis.  The $p$-value of the test statistic that is observed in the actual experiment is calculated by finding its location in the sampling distribution under the null hypothesis. For example, if the observed test statistic is as large or larger than 9,000 of 10,000 simulated experiments, the one-tailed $p$-value is 0.10.
\item What is a 95\% confidence interval?  \\
Answer:\\ 
A confidence interval consists of two estimates, a lower number and an upper number, that are intended to bracket the true parameter of interest with a specified probability. An estimated confidence interval is a random variable that varies from one experiment to the next due to random variability in how units are allocated to treatment and control. A 95\% interval is designed to bracket the true parameter with a 0.95 probability across hypothetical replications of a given experiment.  In other words, across hypothetical replications, 95\% of the estimated 95\% confidence intervals will bracket the true parameter.  
\item How does complete random assignment differ from block random assignment and clustered random assignment?
Answer:\\
Under complete random assignment, each subject is assigned separately to treatment or control groups such that m of N subjects end up in the treatment condition. Under block random assignment, complete random assignment occurs within each block or subgroup. Under clustered assignment, groups of subjects are assigned jointly to treatment or control; the assignment procedure requires that if one member of the group is assigned to the treatment group, all others in the same group are also assigned to treatment. 
\item Experiments that assign the same number of subjects to the treatment group and control group are said to have a ``balanced design.''  What are some desirable statistical properties of balanced designs?\\
Answer:\\
One desirable property of a balanced design is that under certain conditions, it generates less sampling variability than unbalanced designs; this property of balanced designs holds when the variance of $Y_i(0)$ is approximately the same as the variance of $Y_i (1)$. Another attractive property is that estimated confidence intervals are, on average, conservative (they tend to overestimate the true amount of sampling variability) under balanced designs. (A final attractive property, which comes up in Chapter 4, is that regression is less prone to bias under balanced designs.)
\end{enumerate}

\section*{Question 2}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}
\section*{Question 3}
Using the equation $Y_i (1) = Y_i (0) + \tau_i$, show that when we assume that treatment effects are the same for all subjects, 
$Var(Y_i(0))= Var(Y_i(1))$ and the correlation between $Y_i (0)$ and $Y_i (1)$ is 1.0.[5 points]

Under constant treatment effects,  $Var(Y_i (1)=Var(Y_i (0)+\tau)=Var(Y_i (0))$, and the correlation between $Y_i(1)$ and $Y_i(0)$ is:

\begin{align*}
cor(Y_i(1), Y_i(0)) &= \frac{Cov(Y_i(1), Y_i(0))}{\sqrt{Var(Y_i(1)) * Var(Y_i(0))}} \\
&=\frac{Cov(Y_i(0) + \tau, Y_i(0))}{\sqrt{Var(Y_i(0)) * Var(Y_i(0))}} \\
& = \frac{Var(Y_{i}(0))}{Var(Y_{i}(0))}\\
&= 1
\end{align*}

\section*{Question 4}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}

\section*{Question 5}
Using Table 2.1, imagine that your experiment allocates one village to treatment. [10 points]

\begin{enumerate}[a)]
\item Calculate the estimated difference-in-means for all seven possible randomizations.\\
Answer:\\
There are 7 subjects, 1 of which is assigned to treatment, and thus the number of randomizations is $\frac{7!}{1!(7-1)!}=7$. Now let's define $\widehat{ATE_{i}}$ as the difference in means constructed when assuming village i is assigned to treatment.

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{Question 5 Table}
    \begin{tabular}{cccc|l}
    \toprule
     Village & $Y_i(0)$       & $Y_i(1)$    & $\tau_i$        & \multicolumn{1}{c}{$\widehat{ATE_{i}}$} \\
    \midrule
    1     &  10     &  15     & 5      &  $15 - \frac{15+20+20+10+15+15}{6} = -\frac{5}{6}$\\
    2     &  15    &  15     &  0     &  $15 - \frac{10+20+20+10+15+15}{6} = 0$ \\
    3     &  20     & 30      &  10     &  $30 - \frac{10+15+20+10+15+15}{6} = \frac{95}{6}$\\
    4     &   20    &   15    &   -5    &  $15 - \frac{10+15+20+10+15+15}{6} = \frac{5}{6}$\\
    5     &  10      &  20     &  10     &  $20 - \frac{10+15+20+20+15+15}{6} = \frac{25}{6}$\\
    6     & 15      &   15    &   0    & $15 - \frac{10+15+20+20+10+15}{6} = 0$ \\
    7     &   15    &   39    &   15    &  $30 - \frac{10+15+20+20+10+15}{6} = 15$ \\ \midrule
    Mean  &   15    &   20    &   5    & $\frac{-\frac{5}{6} + 0 + \frac{95}{6} + \frac{5}{6} + \frac{25}{6} + 0 + 15}{7} = 5$ \\
    SD    & $\sqrt{\frac{2(10-15)^{2} + 2(20-15)^{2}}{7}}$      &  $\sqrt{\frac{4(15-20)^{2} + 2(30-20)^{2}}{7}}$      &       & $\sqrt{\frac{(-\frac{5}{6}-5)^{2} + 2(-5)^{2} + (\frac{95}{6}-5)^{2} + (\frac{5}{6}-5)^{2}) + (\frac{25}{6}-5)^{2} + (15-5)^{2}}{7}}$ \\
    & $= \sqrt{\frac{100}{7}}$ & $= \sqrt{\frac{300}{7}}$ & &  $= 6.755$\\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

\item Show that the average of these estimates is the true ATE.\\
Answer:\\
The table shows that the average across all randomizations is 5, which is the true ATE.
\item Show that the standard deviation of the seven estimates is identical to the standard error implied by equation (3.4).  

Beginning with Equation 3.4:
\begin{align*}
SE(\widehat{ATE}) &= \sqrt{\frac{1}{(N-1)} \left \{ \frac{mVar(Y_i (0))}{N- m} + \frac{(N-m)*Var(Y_i (1))}{m} + 2cov(Y_i(0), Y_i(1))\right \}} \\
&= \sqrt{\frac{1}{6} \left \{ \frac{Var(Y_i (0))}{6} + 6Var(Y_i (1)) + 2cov(Y_i(0), Y_i(1))\right \}} \\
cov(Y_i(0), Y_i(1)) &= \frac{(10-15)(15-20) + (20-15)(30-20) + (20-15)(15-20)}{7} = \frac{50}{7}\\
&= \sqrt{\frac{1}{6} \left \{ \frac{\frac{100}{7}}{6} + 6\frac{300}{7} + 2\frac{50}{7}\right \}} \\
&= 6.755
\end{align*}

This is identical to the standard deviation calculated in the table above.

\item Referring to equation (3.4), explain why this experimental design has more sampling variability than the design in which two villages out of seven are assigned to treatment.\\
Answer:\\
The covariance term is unaffected, but the first two variance terms are multiplied by different numbers. The first term is multiplied by 1/6 in this example as opposed to 2/5 in the 2-of-7 example. The second term is multiplied by 6/1 in this example as opposed to 5/2 in the 2-of-7 example. Because the second variance term is larger than the first, allocating more sample to the treatment group reduces sampling variance.

\begin{align*}
SE(\widehat{ATE}) &= \sqrt{\frac{1}{(N-1)} \left \{ \frac{mVar(Y_i (0))}{N- m} + \frac{(N-m)*Var(Y_i (1))}{m} + 2cov(Y_i(0), Y_i(1))\right \}} \\
&= \sqrt{\frac{1}{6} \left \{ \frac{1}{6}\frac{100}{7} + \frac{6}{1}\frac{300}{7} + 2\frac{50}{7}\right \}} = 6.755 \text{, if $m = 1$} \\
&= \sqrt{\frac{1}{6} \left \{ \frac{2}{5}\frac{100}{7} + \frac{5}{2}\frac{300}{7} + 2\frac{50}{7}\right \}} = 4.603 \text{, if $m = 2$} \\
\end{align*}

\item Explain why, in this example, a design in which one of seven observations is assigned to treatment has more\footnote{Text mistakenly printed ``less''} sampling variability than a design in which six villages out of seven are assigned to treatment.  

\begin{align*}
SE(\widehat{ATE}) &= \sqrt{\frac{1}{(N-1)} \left \{ \frac{mVar(Y_i (0))}{N- m} + \frac{(N-m)*Var(Y_i (1))}{m} + 2cov(Y_i(0), Y_i(1))\right \}} \\
&= \sqrt{\frac{1}{6} \left \{ \frac{1}{6}\frac{100}{7} + \frac{6}{1}\frac{300}{7} + 2\frac{50}{7}\right \}} = 6.755 \text{, if $m = 1$} \\
&= \sqrt{\frac{1}{6} \left \{ \frac{6}{1}\frac{100}{7} + \frac{1}{6}\frac{300}{7} + 2\frac{50}{7}\right \}} = 4.23 \text{, if $m = 6$} \\
\end{align*}

By the same logic as above -- allocating more units to the condition in which potential outcomes are more variable can reduce sampling variability.

\end{enumerate}

\section*{Question 6}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}

\section*{Question 7}
A diet and exercise program advertises that it causes everyone who is currently dieting to lose at least seven pounds more than they otherwise would have during the first two weeks.  Use randomization inference (the procedure described in section 3.4) to test the hypothesis that $\tau_i=7$ for all $i$.  The treatment group's weight losses after two weeks are (2, 11, 14, 0, 3) and the control group's weight losses are (1, 0, 0, 4, 3).  In order to test the hypothesis $\tau_i=7$ for all $i$ using the randomization inference methods discussed in this chapter, subtract 7 from each outcome in the treatment group so that the exercise turns into the more familiar test of the sharp null hypothesis that $\tau_i=0$ for all $i$. When describing your results, remember to state the null hypothesis clearly, and explain why you chose to use a one-sided or two-sided test. [10 points]

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{Question 7 Table}
    \begin{tabular}{rrrr}
    \toprule
     Subject & $Y_i(0)$      & $Y_i(1)$       & $Y_i(1) - 7$  \\
    \midrule
    1     &   ?    &   2    &  -5 \\
    2     &   ?    &  11     &  4 \\
    3     &   ?    &  14     &  7 \\
    4     &   ?    &  0     &   -7\\
    5     &   ?    &  3     &   -4\\
    6     &   1    &  ?     &   ?\\
    7     &   0    &  ?     & ?  \\
    8     &   0    &  ?     & ?  \\
    9     &   4    &  ?     & ?  \\
    10    &   3    &  ?     & ? \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{1234567}\hlstd{)}
\hlstd{D} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlkwd{rep}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{5}\hlstd{),} \hlkwd{rep}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{5}\hlstd{))}
\hlstd{Y} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{11}\hlstd{,}\hlnum{14}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{3}\hlstd{)}
\hlstd{Y_star} \hlkwb{<-} \hlstd{Y} \hlopt{+} \hlstd{D}\hlopt{*}\hlstd{(}\hlopt{-}\hlnum{7}\hlstd{)}   \hlcom{# Subtracts 7 from "treatment" group}

\hlstd{probs} \hlkwb{<-} \hlkwd{genprobexact}\hlstd{(D)}
\hlstd{ate} \hlkwb{<-} \hlkwd{estate}\hlstd{(Y_star,D,}\hlkwc{prob}\hlstd{=probs)}
\hlstd{perms} \hlkwb{<-} \hlkwd{genperms}\hlstd{(D,}\hlkwc{maxiter}\hlstd{=}\hlnum{10000}\hlstd{)}
\hlstd{Ys} \hlkwb{<-} \hlkwd{genouts}\hlstd{(Y_star,D,}\hlkwc{ate}\hlstd{=}\hlnum{0}\hlstd{)}
\hlstd{distout} \hlkwb{<-} \hlkwd{gendist}\hlstd{(Ys,perms,}\hlkwc{prob}\hlstd{=probs)}
\hlstd{p.value.onesided} \hlkwb{<-} \hlkwd{mean}\hlstd{(distout}\hlopt{<=}\hlstd{ate)}

\hlstd{ate}
\end{alltt}
\begin{verbatim}
## [1] -2.6
\end{verbatim}
\begin{alltt}
\hlstd{p.value.onesided}
\end{alltt}
\begin{verbatim}
## [1] 0.2063492
\end{verbatim}
\end{kframe}
\end{knitrout}

There are 10 subjects, 5 of which are assigned to treatment, and thus the number of randomizations is $\frac{10!}{5!5!}=252$.  The null hypothesis is that the true ATE is a 7 pound loss; the alternative hypothesis is that the weight loss ATE is less than 7 pounds.  A one-sided hypothesis test is used because we only want to reject the weight loss program's claims if the observed weight loss is less than what they claimed; if they understated the degree of weight loss, their program would be even more effective than claimed, and one would hardly fault them for that.  Using the code for randomization inference posted on the website, we find that the observed difference in weight loss between the treatment and control groups (6 - 1.6 = 4.4) is smaller than 79\% of all simulated experiments under the null hypothesis of a 7 pound effect for everyone.  Thus, the p-value is 0.21, meaning we cannot reject the null hypothesis of a 7-pound effect at the conventional 0.05 significance threshold.

\section*{Question 8}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}

\section*{Question 9}

Camerer reports the results of an experiment in which he tests whether large, early bets placed at horse tracks affect the betting behavior of other bettors.\footnote{Camerer 1998.  This example draws on the second of Camerer's studies and restricts the sample to cases in which a treatment horse is compared to a single control horse.} Selecting pairs of long-shot horses running in the same race whose betting odds were approximately the same when betting opened, he placed two \$500 bets on one of the two horses approximately 15 minutes before the start of the race. Because odds are determined based on the proportion of total bets placed on each horse, this intervention causes the betting odds for the treatment horse to decline and the betting odds of the control horse to rise. Because Camerer's bets were placed early, when the total betting pool was small, his bets caused marked changes in the odds presented to other bettors. (A few minutes before each race started, Camerer canceled his bets.) While the experimental bets were still ``live,'' were other bettors attracted to the treatment horse (because other bettors seemed to believe in the horse) or repelled by it (because the diminished odds meant a lower return for each wager)? Seventeen pairs of horses in this study are listed below. The outcome measure is the number of dollars that were placed on each horse (not counting Camerer's own wagers on the treatment horses) during the test period, which begins 16 minutes before each race (roughly 2 minutes before Camerer began placing his bets) and ends 5 minutes before each race (roughly 2 minutes before Camerer withdrew his bets). [10 points]

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[H]
  \centering
  \caption{Question 9 Table}
    \begin{tabular}{rR{2cm}R{1.8cm}R{1.5cm}R{2cm}R{1.8cm}R{1.5cm}R{1.8cm}}
    \toprule
    & \multicolumn{3}{c}{Treatment Horse in Pair}& \multicolumn{3}{c}{Control Horse in Pair} \\ \cmidrule(r){2-4}\cmidrule(r){5-7}
          & Total bets $T-16$ min & Total bets $T-5$ min & Change & Total bets $T-16$ min & Total bets $T-5$ min & Change & Difference in changes \\
    \midrule
    Pair 1 & 533   & 1503  & 970   & 587   & 2617  & 2030  & -1060 \\
    Pair 2 & 376   & 1186  & 810   & 345   & 1106  & 761   & 49 \\
    Pair 3 & 576   & 1366  & 790   & 653   & 2413  & 1760  & -970 \\
    Pair 4 & 1135  & 1666  & 531   & 1296  & 2260  & 964   & -433 \\
    Pair 5 & 158   & 367   & 209   & 201   & 574   & 373   & -164 \\
    Pair 6 & 282   & 542   & 260   & 269   & 489   & 220   & 40 \\
    Pair 7 & 909   & 1597  & 688   & 775   & 1825  & 1050  & -362 \\
    Pair 8 & 566   & 933   & 367   & 629   & 1178  & 549   & -182 \\
    Pair 9 & 0     & 555   & 555   & 0     & 355   & 355   & 200 \\
    Pair 10 & 330   & 786   & 456   & 233   & 842   & 609   & -153 \\
    Pair 11 & 74    & 959   & 885   & 130   & 256   & 126   & 759 \\
    Pair 12 & 138   & 319   & 181   & 179   & 356   & 177   & 4 \\
    Pair 13 & 347   & 812   & 465   & 382   & 604   & 222   & 243 \\
    Pair 14 & 169   & 329   & 160   & 165   & 355   & 190   & -30 \\
    Pair 15 & 41    & 297   & 256   & 33    & 75    & 42    & 214 \\
    Pair 16 & 37    & 71    & 34    & 33    & 121   & 88    & -54 \\
    Pair 17 & 261   & 485   & 224   & 282   & 480   & 198   & 26 \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}

\begin{enumerate}[a)]
\item One interesting feature of this study is that each pair of horses ran in the same race.  Does this design feature violate the non-interference assumption, or can potential outcomes be defined so that the non-interference assumption is satisfied? \\
Answer:\\
This design feature violates non-interference if the estimand is defined as the difference between the following two potential outcomes: total bets on a given horse when experimental bets are placed on that horse versus no experimental bets on any horse in the race.  One could avoid violating non-interference by redefining the estimand as the difference between the following two potential outcomes: total bets on a horse when experimental bets are placed on that horse versus experimental bets are placed on a competing horse in the same race. 

\item A researcher interested in conducting a randomization check might assess whether, as expected, treatment and control horses attract similarly sized bets prior to the experimental intervention.  Use randomization inference to test the sharp null hypothesis that the bets had no effect prior to being placed. \\

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{D} \hlkwb{<-}  \hlstd{camerer}\hlopt{$}\hlstd{treatment}
\hlstd{block} \hlkwb{<-} \hlstd{camerer}\hlopt{$}\hlstd{pair}
\hlstd{covs} \hlkwb{<-} \hlkwd{as.matrix}\hlstd{(camerer}\hlopt{$}\hlstd{preexperimentbets)}

\hlstd{probs} \hlkwb{<-} \hlkwd{genprobexact}\hlstd{(D,}\hlkwc{blockvar}\hlstd{=block)}
\hlstd{perms} \hlkwb{<-} \hlkwd{genperms}\hlstd{(D,}\hlkwc{maxiter}\hlstd{=}\hlnum{10000}\hlstd{,}\hlkwc{blockvar}\hlstd{=block)}
\end{alltt}
\begin{verbatim}
## Too many permutations to use exact method.
## Defaulting to approximate method.
## Increase maxiter to at least 131072 to perform exact estimation.
\end{verbatim}
\begin{alltt}
\hlstd{numiter} \hlkwb{<-} \hlkwd{ncol}\hlstd{(perms)}

\hlstd{Fstat} \hlkwb{<-} \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(D}\hlopt{~}\hlstd{covs))}\hlopt{$}\hlstd{fstatistic[}\hlnum{1}\hlstd{]}
\hlstd{Fstatstore} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{NA}\hlstd{,numiter)}

\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{numiter) \{}
  \hlstd{Fstatstore[i]} \hlkwb{<-} \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(perms[,i]}\hlopt{~}\hlstd{covs))}\hlopt{$}\hlstd{fstatistic[}\hlnum{1}\hlstd{]}
        \hlstd{\}}

\hlstd{p.value} \hlkwb{<-} \hlkwd{mean}\hlstd{(Fstatstore} \hlopt{>=} \hlstd{Fstat)}
\hlstd{p.value}
\end{alltt}
\begin{verbatim}
## [1] 0.3696
\end{verbatim}
\end{kframe}
\end{knitrout}

We conducted 10,000 random assignments, and for each we calculated the F-statistic of a regression of treatment assignment on pre-experimental bets (controlling for blocks).  The observed F-statistic for the actual experiment is larger than 3696 of the simulated experiments, implying a p-value of 0.37.

\item Calculate the average increase in bets during the experimental period for treatment horses and control horses.  Compare treatment and control means, and interpret the estimated ATE.  
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{change} \hlkwb{<-} \hlstd{camerer}\hlopt{$}\hlstd{change}
\hlstd{change_treatment} \hlkwb{<-} \hlkwd{mean}\hlstd{(change[D}\hlopt{==}\hlnum{1}\hlstd{])}
\hlstd{change_control} \hlkwb{<-} \hlkwd{mean}\hlstd{(change[D}\hlopt{==}\hlnum{0}\hlstd{])}
\hlstd{ATE} \hlkwb{<-} \hlstd{change_treatment} \hlopt{-} \hlstd{change_control}
\hlstd{ATE}
\end{alltt}
\begin{verbatim}
## [1] -110.1765
\end{verbatim}
\end{kframe}
\end{knitrout}
The average treatment group change was \$461.24, as opposed to an average change of \$571.41 in the control group.  Therefore, the estimated ATE is \$\ensuremath{-110.18}.
\item Show that the estimated ATE is the same when you subtract the control group outcome from the treatment group outcome for each pair and calculate the average difference for the 17 pairs. 
Answer:\\
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pair_diffs} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{NA}\hlstd{,} \hlnum{17}\hlstd{)}

\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{17}\hlstd{)\{}
\hlstd{pair_diffs[i]} \hlkwb{<-} \hlkwd{diff}\hlstd{(change[block}\hlopt{==}\hlstd{i])}
\hlstd{\}}

\hlkwd{mean}\hlstd{(pair_diffs)}
\end{alltt}
\begin{verbatim}
## [1] 110.1765
\end{verbatim}
\end{kframe}
\end{knitrout}
The average difference between treatment and control outcomes for each pair is also 110.18.

\item Use randomization inference to test the sharp null hypothesis of no treatment effect for any subject.  When setting up the test, remember to construct the simulation to account for the fact that random assignment takes place within each pair.  Interpret the results of your hypothesis test and explain why a two-tailed test is appropriate in this application.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{1234567}\hlstd{)}
\hlstd{probs} \hlkwb{<-} \hlkwd{genprobexact}\hlstd{(D,}\hlkwc{blockvar}\hlstd{=block)} \hlcom{# Notice the blocks}
\hlstd{ate} \hlkwb{<-} \hlkwd{estate}\hlstd{(change,D,}\hlkwc{prob}\hlstd{=probs)}
\hlstd{perms} \hlkwb{<-} \hlkwd{genperms}\hlstd{(D,}\hlkwc{maxiter}\hlstd{=}\hlnum{10000}\hlstd{,}\hlkwc{blockvar}\hlstd{=block)}
\end{alltt}
\begin{verbatim}
## Too many permutations to use exact method.
## Defaulting to approximate method.
## Increase maxiter to at least 131072 to perform exact estimation.
\end{verbatim}
\begin{alltt}
\hlstd{Ys} \hlkwb{<-} \hlkwd{genouts}\hlstd{(change,D,}\hlkwc{ate}\hlstd{=}\hlnum{0}\hlstd{)}
\hlstd{distout} \hlkwb{<-} \hlkwd{gendist}\hlstd{(Ys,perms,}\hlkwc{prob}\hlstd{=probs)}

\hlstd{ate}
\end{alltt}
\begin{verbatim}
## [1] -110.1765
\end{verbatim}
\begin{alltt}
\hlstd{p.value} \hlkwb{<-} \hlkwd{mean}\hlstd{(}\hlkwd{abs}\hlstd{(distout)} \hlopt{>=} \hlkwd{abs}\hlstd{(ate))}
\hlstd{p.value}
\end{alltt}
\begin{verbatim}
## [1] 0.3092
\end{verbatim}
\end{kframe}
\end{knitrout}
A two-tailed test generates a p-value of 0.3092, indicating that one cannot reject the sharp null of no effect for any unit. A two-tailed test is appropriate because some theories predict a positive effect while others predict a negative effect: ``were other bettors attracted to the treatment horse (because other bettors seemed to believe in the horse) or repelled by it (because the diminished odds meant a lower return for each wager)?''  The appropriate null hypothesis in this case is no effect, which would be rejected if we observed either strongly positive or strongly negative differences between treatment and control horses.
\end{enumerate}

\section*{Question 10}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}

\section*{Question 11}

Use the data in Table 3.3 to simulate cluster randomized assignment. [10 points]

\begin{enumerate}[a)]
\item Suppose that clusters are formed by grouping observations $\{1,2\},\{3,4\},\{5,6\}\ldots\{13,14\}$.  Use equation (3.22) to calculate the standard error assuming half of the clusters are randomly assigned to the treatment.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{Y0} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{9}\hlstd{,}\hlnum{14}\hlstd{,}\hlnum{15}\hlstd{,}\hlnum{16}\hlstd{,}\hlnum{16}\hlstd{,}\hlnum{17}\hlstd{,}\hlnum{18}\hlstd{)}
\hlstd{Y1} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{12}\hlstd{,}\hlnum{9}\hlstd{,}\hlnum{8}\hlstd{,}\hlnum{15}\hlstd{,}\hlnum{5}\hlstd{,}\hlnum{17}\hlstd{)}
\hlstd{cluster} \hlkwb{<-} \hlkwd{rep}\hlstd{(}\hlnum{1}\hlopt{:}\hlnum{7}\hlstd{,} \hlkwc{each}\hlstd{=}\hlnum{2}\hlstd{)}
\hlstd{Ybar0} \hlkwb{<-} \hlkwd{tapply}\hlstd{(}\hlkwc{X}\hlstd{=Y0,} \hlkwc{INDEX}\hlstd{=cluster,} \hlkwc{FUN}\hlstd{=mean)}
\hlstd{Ybar1} \hlkwb{<-} \hlkwd{tapply}\hlstd{(}\hlkwc{X}\hlstd{=Y1,} \hlkwc{INDEX}\hlstd{=cluster,} \hlkwc{FUN}\hlstd{=mean)}

\hlstd{var.pop} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)\{}\hlkwd{sum}\hlstd{((x}\hlopt{-}\hlkwd{mean}\hlstd{(x))}\hlopt{^}\hlnum{2}\hlstd{)}\hlopt{/}\hlstd{(}\hlkwd{length}\hlstd{(x))\}}
\hlstd{cov.pop} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{,}\hlkwc{y}\hlstd{)\{}\hlkwd{sum}\hlstd{((x}\hlopt{-}\hlkwd{mean}\hlstd{(x))}\hlopt{*}\hlstd{(y}\hlopt{-}\hlkwd{mean}\hlstd{(y)))}\hlopt{/}\hlstd{(}\hlkwd{length}\hlstd{(x))\}}

\hlstd{var_Ybar0} \hlkwb{<-} \hlkwd{var.pop}\hlstd{(Ybar0)}
\hlstd{var_Ybar1} \hlkwb{<-} \hlkwd{var.pop}\hlstd{(Ybar1)}
\hlstd{cov_Ybar0} \hlkwb{<-} \hlkwd{cov.pop}\hlstd{(Ybar0,Ybar1)}

\hlstd{se_ate} \hlkwb{<-} \hlkwd{sqrt}\hlstd{((}\hlnum{1}\hlopt{/}\hlnum{6}\hlstd{)} \hlopt{*} \hlstd{((}\hlnum{4}\hlopt{/}\hlnum{3}\hlstd{)}\hlopt{*}\hlstd{var_Ybar0} \hlopt{+} \hlstd{(}\hlnum{3}\hlopt{/}\hlnum{4}\hlstd{)}\hlopt{*}\hlstd{var_Ybar1} \hlopt{+} \hlnum{2}\hlopt{*}\hlstd{cov_Ybar0))}
\hlstd{se_ate}
\end{alltt}
\begin{verbatim}
## [1] 4.706192
\end{verbatim}
\end{kframe}
\end{knitrout}

Assuming that 4 out of 7 clusters are assigned to treatment, the standard error of the ATE will be 4.71.

\item Suppose that clusters are instead formed by grouping observations $\{1,14\},\{2,13\},\{3,12\}\ldots\{7,8\}$. Use equation (3.22) to calculate the standard error assuming half of the clusters are randomly assigned to the treatment.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{cluster} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{5}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{7}\hlstd{,}\hlnum{7}\hlstd{,}\hlnum{6}\hlstd{,}\hlnum{5}\hlstd{,}\hlnum{4}\hlstd{,}\hlnum{3}\hlstd{,}\hlnum{2}\hlstd{,}\hlnum{1}\hlstd{)}
\hlstd{Ybar0} \hlkwb{<-} \hlkwd{tapply}\hlstd{(}\hlkwc{X}\hlstd{=Y0,} \hlkwc{INDEX}\hlstd{=cluster,} \hlkwc{FUN}\hlstd{=mean)}
\hlstd{Ybar1} \hlkwb{<-} \hlkwd{tapply}\hlstd{(}\hlkwc{X}\hlstd{=Y1,} \hlkwc{INDEX}\hlstd{=cluster,} \hlkwc{FUN}\hlstd{=mean)}

\hlstd{var_Ybar0} \hlkwb{<-} \hlkwd{var.pop}\hlstd{(Ybar0)}
\hlstd{var_Ybar1} \hlkwb{<-} \hlkwd{var.pop}\hlstd{(Ybar1)}
\hlstd{cov_Ybar0} \hlkwb{<-} \hlkwd{cov.pop}\hlstd{(Ybar0,Ybar1)}

\hlstd{se_ate} \hlkwb{<-} \hlkwd{sqrt}\hlstd{((}\hlnum{1}\hlopt{/}\hlnum{6}\hlstd{)} \hlopt{*} \hlstd{((}\hlnum{4}\hlopt{/}\hlnum{3}\hlstd{)}\hlopt{*}\hlstd{var_Ybar0} \hlopt{+} \hlstd{(}\hlnum{3}\hlopt{/}\hlnum{4}\hlstd{)}\hlopt{*}\hlstd{var_Ybar1} \hlopt{+} \hlnum{2}\hlopt{*}\hlstd{cov_Ybar0))}
\hlstd{se_ate}
\end{alltt}
\begin{verbatim}
## [1] 0.9766259
\end{verbatim}
\end{kframe}
\end{knitrout}

Assuming that 4 out of 7 clusters are assigned to treatment, the standard error of the ATE will be 0.98.

\item Why do the two methods of forming clusters lead to different standard errors? What are the implications for the design of cluster randomized experiments?\\
Answer:\\
The first method clusters the most similar villages together, and the second method clusters the most dissimilar villages together. As a result, the variances of the average within-cluster potential outcomes are much larger in the first method and smaller in the second. As a result, the second method produces a much narrower standard error of the ATE estimate. The implication for clustered design is that the more similar the observations with a cluster, the less precise the estimates we can produce. When possible, cluster heterogeneous observations together.
\end{enumerate}

\section*{Question 12}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}





\end{verbatim}
\end{kframe}
\end{knitrout}

\end{document}
