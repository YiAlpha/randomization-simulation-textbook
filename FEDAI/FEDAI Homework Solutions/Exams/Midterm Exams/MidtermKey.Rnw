% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM SET LATEX TEMPLATE FILE
% DEFINE DOCUMENT STYLE, LOAD PACKAGES
\documentclass[11pt,notitlepage]{article}    % ADD COMMENTS USING A PERCENT SIGN
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath, booktabs}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{subfig}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multicol}
\usepackage{multirow}
\setlength{\parindent}{0in}  	% uncomment to remove indent at start of paragraphs
\usepackage{pdflscape}
\usepackage[english]{babel}
\usepackage[pdftex]{hyperref}
\usepackage{natbib}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphics}
\usepackage{multirow}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{latexsym}
\usepackage{rotating}
\usepackage{setspace}
\usepackage{layouts} 
\usepackage[titletoc]{appendix}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage[margin=1in]{geometry}
\usepackage{enumerate}
\usepackage{float}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage[T1]{fontenc}				

<<setup, include=FALSE, cache=FALSE>>=
rm(list=ls())
library(knitr)
library(foreign)
library(xtable)
library(stargazer)

# set global chunk options
opts_chunk$set(fig.path='figure/midterm', fig.align='center', fig.show='hold', out.width = '4in', out.height='4in', tidy=FALSE)
options(replace.assign=TRUE,width=90)
@




% DEFINE WHAT GOES INTO YOUR TITLE BEFORE THE DOCUMENT BEGINS
\title{POLS 4368 - Fall 2014 Midterm Solution Set}
\author{Professor Donald P. Green \\
TA Alex Coppock}
\date{\today}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

This exam reviews concepts from FEDAI Chapters 1-6.  At the conclusion of this exam, please turn in this sheet along with your blue exam booklet.
\section{Section I}
Briefly define and state the significance of the following terms or phrases.  Use formal notation to make your definitions as clear as possible. (9 points each)
\begin{enumerate}
\item Randomization inference\\
Answer:\\
Randomization inference is procedure for constructing 95\% confidence intervals and conducting hypothesis tests. Subjects reveal one of two potential outcomes depending on their treatment assignment: treated subjects reveal their $Y_i(1)$ and untreated subjects reveal their $Y_i(0)$. Randomization inference proceeds by hypothesing what the \textit{other} potential outcome is for each subject.  When constructing 95\% condifence, we fill in the missing potential outcome using the estimated treatment effect -- subtracting it off for treated subjects and adding back for untreated subjects. We can then generate the sampling distribution of the experiment under all possible random assignments -- that is, under the hypothesis of constant effects (equal to the estimated ATE), all the ways the experiment could have turned out. Each possible random assignment generates a simulated ATE -- the 95\% confidence interval is the range extending from the 2.5\textsuperscript{th} percentile to the 97.5\textsuperscript{th}.\\

Hypothesis tests conducted using randomization inference, on the other hand, are carried out by supposing the sharp null hypothesis of no effect, i.e., that there is exactly zero treatment effect for all subjects. The sharp null implies that the missing potential outcome is the same as the observed potential outcome. We can then generate the sampling distribution under the sharp null by considering the estimated ATEs under all possible random assignments. The $p$-value we assign to the estimated ate is the fraction of simulated ATEs that equal or exceed the observed ATE. For two-tailed tests, we calculated the fraction of simulated ATEs that equal or exceed the observed ATE in absolute value.

\item Covariate adjustment\\
Answer:\\

Covariate adjustment is a statisical procedure employed to dampen sampling variability. When researchers adjust for pre-treatment covariates that are prognostic of the outcome, the sampling distribution around the estimated ATE is tighter. Adjusting for covariates is method of rescaling the dependent variable so we can focus on the variation induced by treatment, rather than the variation that is correlated with background attributes.  Covariate adjustment can also help to provide greater balance on observable characteriscs that may be slighly imbalanced across treatment and control due to chance.  Covariate adjustment does introduce Freeman bias (the average of the covariate-adjusted estimates over all possible randomizations is not exactly equal to the true ATE), the size of this bias is small and diminishes rapidly as N rises above 20.  An important point to underscore in the discussion of covariates is that the estimated coefficients on the covariates should never be given any causal interpretation -- they included only to reduce sampling variability.  Finally, researchers should pre-register which covariates they intend to use so as to reduce the researcher discretion and suspicion of fishing.

\item Clustered random assignment\\
Answer:\\
When treatment assignment occurs at the group or cluster level, it is refered to as clustered random assignment. A canonical example is experiments in schools -- treatment is often assigned at the classroom level rather than at the school level. Clustered assignment, relative to individual-level treatment assignment, often increases sampling variability. The worst case is when all the individuals within a cluster have similar potential outcomes, but potential outcomes across clusters vary widely.  In this case, the effective N of the experiment is closer to the number of clusters rather than the number of individuals. When potential outcomes are more homogenous across clusters, the effective N is higher.

Another trouble with cluster random assignment when clusters are of unequal size is that the difference-in-means estimator of the ATE is biased.  This is because the denominator in each group is a random variable (i.e., the number of subjects in the treatment group varies depending on which clusters happen to be treated.).  The expectation of a ratio is not, in general, the ratio of the expectations.  There are two recommendations for addressing this problem.  The first is design-based: perform block random assignment by cluster size -- obviating the changing denominator problem.  The second is an analytic recommendation to use the Horvitz-Thompson difference-in-totals estimator, which is less efficient than difference-in-means, but is unbiased even in the presence of clusters of unequal size.

\item The assumption of monotonicity in the context of two-sided noncompliance
Answer:\\
In experiments facing two-sided non-compliance, subjects can be assigned to treatment or control ($Z=1$ or $Z=0$), and they can either take treatment or not ($D=1$ or $D=0$).  This creates four types: Always-takers ($D(Z=1) = D(Z=0) = 1$), Compliers ($D(Z=1) = 1$; $D(Z=0) = 0$), Never-takers ($D(Z=1) = D(Z=0) = 0$), and Defiers ($D(Z=1) = 0$; $D(Z=0) = 1$). Formally, the assumption of monotonicity can be stated in the following manner: $D(Z=1) \geq D(Z=0)$. This restriction rules out one of the four types: the defiers.  This assumption is crucial for the identication of the Complier Average Causal Effect using experimental data -- without it, we can't identify the average effects of treatment for any group.

\end{enumerate}
\newpage
\section{Section II}
The following table was presented in Chapter 5. The results refer to the New Haven voter mobilization experiment, in which a random subset of the subject pool was assigned to be canvassed, but only some of those assigned to be canvassed were actually canvassed.  The outcome is voter turnout. (8 points each)


\begin{table}[H]
\caption*{Voter turnout by experimental group, New Haven voter mobilization experiment}
\centering
    \begin{tabular}{lll}
    ~                                                    & Treatment Group & Control Group \\ \hline
    Turnout rate among those contacted by canvassers     & 54.43 (395)     & ~             \\
    Turnout rate among those not contacted by canvassers & 36.48 (1,050)   & 37.54 (5,645) \\
    Overall turnout rate                                 & 41.38 (1,445)   & 37.54 (5,645) \\ \hline
    \multicolumn{3}{l}{Note: Entries are percent voting, with number of observations in parentheses.}\\
     \multicolumn{3}{l}{Sample restricted to households containing a single registered voter.}
    \end{tabular}
\end{table}
\begin{enumerate}
\item Define a ``Complier.''\\
Answer:\\
A complier is a subject who takes treatment if and only assigned to the treatment group.  In this case, a complier is a subject who opens the door to a canvasser if and only if assigned to the treatment group.  

\item Estimate the proportion of Compliers in the subject pool.

<<2b, cache=TRUE>>=
pr.compliers <- 395/1445
pr.compliers
@

The proportion of compliers is $\Sexpr{round(pr.compliers, 3)}.

\item Show (with algebra) that under the assumption of non-interference and excludability, the CACE is identified in this application.\\

The CACE is defined as $E(Y_i(1)-Y_i(0)|D_i(1)=1)$.\\
\begin{itemize}
\item Expected value of voting rate ($Y$) in the control group = \\
$E(Y_i(0)|D_i(1)=1)*ITT_d + E(Y_i(0)|D_i(1)=0)*(1-ITT_d)$\\
\item Expected value of voting rate in treatment group = \\
$E(Y_i(1)|D_i(1)=1)*ITT_d + E(Y_i(0)|D_i(1)=0)*(1-ITT_d)$\\
\item Expected value of rate of successful canvassing = $E(D_i(1)) = ITT_d$\\
\item Expected value of voting rate among treatment group minus voting rate of control group = $(E(Y_i(1)|D_i(1)=1) - E(Y_i(0)|D_i(1)=1))*(ITT_d) = CACE*ITT_d$.  \\
\item $CACE = (E(Y_i(1)|D_i(1)=1) - E(Y_i(0)|D_i(1)=1)) / (ITT_d)$.\\
\end{itemize}

\item Are non-interference and excludability plausible in this example?\\
Answer:\\
Non-interference requires that the subjects respond only to their own treatment assignment, and not to the treatment assignment of others. This would be violated if, perhaps, neighbors called each other after being canvassed and talked about voting. The possibility of interference was explored experimentally by Sinclair, McConnell, and Green (2012) -- Having treated neighbors does not appear to increase turnout.
Excludability requires that nothing about assignment to canvassing itself affected potential outcomes, only the canvassing itself. This is plausible in this experiment.

\item Estimate (by hand) the CACE. Provide a substantive interpretation of your estimate.

<<2d, cache=TRUE>>=
itt <- .4138 - .3754
ittd <- 395/1445
cace <- itt/ittd
cace
@

The $\widehat{CACE}$ is \Sexpr{round(cace, 3)}, meaning that compliers are \Sexpr{round(100*cace, 1)} percentage points more likely to vote as a result of canvassing.

\end{enumerate}

\section{Section III}
A recent experiment tested the effects of sending registered voters in New York City a (nonpartisan) postcard that encouraged them to donate to the candidate of their choice, on the grounds that small donations keep elected officials focused on important policy issues. Randomization was conducted within each of 5 blocks; blocks were created based on voters' expected probability of donating to campaigns in the future. Below is a block-by-block summary of the results. The first table displays the distribution of donations in control and treatment, by block. The next table displays the results of regressions, by block, of donations on treatment. The third table displays the results of inverse-probability weighted regression and the accompanying p-values derived from randomization inference under the sharp null hypothesis of no effect. The last table presents the results of an unweighted regression that controls for blocks. Based on your reading of the tables, answer the following questions: [8 points each]

\begin{enumerate}
\item Why would an (unweighted) regression of donations on treatment, ignoring blocking, be a biased estimator of the average treatment effect?\\
Answer:\\
Because the blocks are of unequal size, the probabilities of assignment to treatment differ by block. If treatment effects vary by block, then an unweighted regression would be biased because of the induced correlation between potential outcomes and treatment assignment.
\item Interpret the third table's estimate of the ATE and the accompanying p-value.\\
Answer:\\ 
The treatment postcards raised the amount individuals donated to campaigns by \$3.82. This result is unlikely under the null model that the postcards had zero effect for all units -- only 3.17\% of simulations under the null returned difference-in-means estimates as large or larger than \$3.82 in absolute value.

\item The block-by-block regressions seem to suggest that the postcard has a significantly negative effect on donations in blocks 1 and 4. The $p$-values based on robust standard errors are below 0.05. Yet the overall estimate of the ATE using inverse-probability weights is positive. What do you think accounts for this apparent discrepancy?\\
Answer:
Treatment effects appear to vary by block -- there is nothing about a positive average effect that precludes the treatment from having a negative effect among some individuals.

\item Bonus: The weighted regression presented in table 3 produces an estimated ATE that is different from an unweighted regression (presented in table 4) that controls for blocks by using a dummy variable for each block (except one, which is the intercept). What, specifically, about the two regressions causes them to produce different estimates? (3 points)\\
Answer:\\
The two regressions use different weighting schemes.  The IPW regression uses inverse probability weighting to stich together the blocks of the experiment. The regression in table 4 weights each block proportionally to the precision with which the treatment effect is estimated. The two answers are similar because, by and large, as N increases, so does the precision of the estimate. The estimands are also different.  Table three presents an estimate of the average individual treatment effect.Table four presents an average of the block-level average treatment effects.


\end{enumerate}

<<Q3setup,cache=FALSE,include=FALSE>>=
rm(list=ls())
library(foreign)
library(ri)
library(plyr)
library(xtable)
library(sandwich)
library(lmtest)
library(stargazer)
setwd("~/Documents/Dropbox/Columbia/spring 2014/experiments2014/fedai homework solutions/Exams/")
nyc <- read.dta("NYC Fundraising --blocking example.dta")
nyc <- within(nyc,{
  block <- as.character(block)
})
@

<<Q3table1,cache=TRUE,results='asis',echo=FALSE>>=
blockmeans <- ddply(nyc, c("block"), summarize,
                    control_mean = mean(amount_donated[policy_postcard==0]),
                    control_sd = sd(amount_donated[policy_postcard==0]),
                    control_n = length(amount_donated[policy_postcard==0]),
                    treatment_mean = mean(amount_donated[policy_postcard==1]),
                    treatment_sd = sd(amount_donated[policy_postcard==1]),
                    treatment_n = length(amount_donated[policy_postcard==1]))

print(xtable(blockmeans,caption="Distribution of Donations, by Experimental Group"), include.rownames=FALSE, caption.placement="top")
@

<<Q3table2,cache=TRUE,results='asis',echo=FALSE>>=
fit.1 <- lm(amount_donated ~ policy_postcard, data=subset(nyc, block==1))
fit.2 <- lm(amount_donated ~ policy_postcard, data=subset(nyc, block==2))
fit.3 <- lm(amount_donated ~ policy_postcard, data=subset(nyc, block==3))
fit.4 <- lm(amount_donated ~ policy_postcard, data=subset(nyc, block==4))
fit.5 <- lm(amount_donated ~ policy_postcard, data=subset(nyc, block==5))

commarobust <- function(fit){
  coeftest(fit,vcovHC(fit,type="HC1"))
}

fit.1.r <- commarobust(fit.1)
fit.2.r <- commarobust(fit.2)
fit.3.r <- commarobust(fit.3)
fit.4.r <- commarobust(fit.4)
fit.5.r <- commarobust(fit.5)

stargazer(fit.1, fit.2, fit.3, fit.4, fit.5,omit.stat = c("f", "adj.rsq", "ser"), style="apsr",column.sep.width="0pt",
          covariate.labels=c("Treatment", "Constant"),title="Block by Block regressions",
          dep.var.labels="Amount Donated", 
          column.labels=c("Block 1", "Block 2", "Block 3","Block 4","Block 5"), model.numbers=FALSE,
          notes = "Robust Standard Errors in Parentheses",
          se=list(fit.1.r[,2],fit.2.r[,2],fit.3.r[,2],fit.4.r[,2],fit.5.r[,2]))
@


<<Q3table3,cache=TRUE,results='asis',echo=FALSE>>=
set.seed(343)
Z <- nyc$policy_postcard
block <- nyc$block
Y <- nyc$amount_donated

probs <- genprobexact(Z=Z, blockvar=block)
ate <- estate(Y=Y, Z=Z, prob=probs)
#perms <- genperms(Z=Z, blockvar=block, maxiter=100)
#Ys <- genouts(Y=Y, Z=Z, ate=0)
#distout <- gendist(Ys=Ys, perms=perms,prob=probs)
#pvalue.2sided <- mean(abs(distout) >= abs(ate))

table3 <- rbind(ate, 0.0317)
rownames(table3) <- c("Estimate from inverse probability weighted regression", "Two-sided p-value from randomization inference")

print(xtable(table3, digits=4, caption="Randomization Inference on IPW estimate"),include.colnames=FALSE, caption.placement="top")
@

<<Q3table4,cache=TRUE,results='asis',echo=FALSE>>=
set.seed(343)
fit.all <- lm(Y ~ Z + as.factor(block), data=nyc)
fit.all.r <- commarobust(fit.all)

print(xtable(fit.all.r[], digits=4, caption="Unweighted Regression Controlling for Blocks"), caption.placement="top")

@

\end{document}


