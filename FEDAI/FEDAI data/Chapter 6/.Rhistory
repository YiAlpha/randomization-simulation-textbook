# canned procedures for calculating the SD divide by N-1
# because they assume that a sample has been drawn
sd(pop_values)
sample_size <- 100
sample_values <- sample(pop_values,size=sample_size,replace=FALSE)
# display the resulting sample
sample_values
# how close is the sample mean to the true population mean?
mean(sample_values)
hist(sample_values, breaks=10)
# Estimate the standard error of the estimated mean
# using the formula in the Freedman et al. book
# note that this estimator presupposes simple random sampling with a low sampling ratio
est_SE <- (var(sample_values)/sample_size)^.5
est_SE
numiter <- 100000
# number of iterations - want to make this as large as possible
storemean <- storese <- rep(NA,numiter)
for (iter in 1:numiter) {
sample_values <- sample(pop_values,size=sample_size,replace=FALSE)
storemean[iter] <- mean(sample_values)
storese[iter] <- (var(sample_values)/sample_size)^.5
}
mean(storemean)  # the average estimate should be very close to the true population mean
sd(storemean) # (approximately) the true standard error of the sampling distribution
plot(density(storemean)) # becomes approximately normal as sample_size increases
mean(storese) # E[standard error estimator]
hist(storese) # Also has a distribution! Lots of variability.
# Simulate properties of a simple random sample in order to
# illustrate the advantages of stratified random sampling
# create a "population" from which we will draw a sample
pop_values <- seq(1,10000, by=1)
strata <- rep(0:1, each=5000)
hist(pop_values,breaks=20)  # notice that the population distribution is uniform
# display the population distribution, using shading for each stratum
p1 <- hist(pop_values[strata==0])
p2 <- hist(pop_values[strata==1])
plot(p1, col=rgb(0,0,1,1/4), xlim=c(0,10000))
plot(p2, col=rgb(1,0,0,1/4), xlim=c(0,10000), add=T)
mean(pop_values)  # calculate the mean of the population
nrow(as.matrix(pop_values))  # calculate the number of elements in the population
summary(pop_values[strata==0])  # summarize the population in the first stratum
summary(pop_values[strata==1])  # summarize the population in the second stratum
# first: calculate sigma
sigma <- sqrt(sum((pop_values - mean(pop_values))^2)/nrow(as.matrix(pop_values)))  # to find the population standard deviation (divide by N, not N-1, because mean is not estimated)
sigma  # standard deviation
# determine the N
sample_size <- 100
true_SE <- sigma/sqrt(sample_size)  # true standard error under simple random sampling
true_SE
# start with stratum 1
sample_values_1 <- sample(pop_values[strata==0],size=sample_size/2,replace=FALSE)
# display the resulting sample
sample_values_1
# next, sample from the other stratum
sample_values_2 <- sample(pop_values[strata==1],size=sample_size/2,replace=FALSE)
# display the resulting sample
sample_values_2
# plot the combined sample, shading observations drawn from each stratum
p1 <- hist(sample_values_1,10)
p2 <- hist(sample_values_2,10)
plot(p1, col=rgb(0,0,1,1/4), xlim=c(0,10000))
plot(p2, col=rgb(1,0,0,1/4), xlim=c(0,10000), add=T)
# combine the two samples into a single overall sample
sample_values <- c(sample_values_1,sample_values_2)
# how close is the sample mean to the true population mean?
mean(sample_values)
mean(pop_values)
# use a "loop" to simulate what would happen if we were to replicate our sampling procedure a large number of times
numiter <- 100000
# number of iterations - want to make this as large as possible (if you have time to wait)
storemean <- storeSRSmean <- rep(NA,numiter)  # initialize the output variables as NA values at the outset
for (iter in 1:numiter) {
sample_values_1 <- sample(pop_values[strata==0],size=sample_size/2,replace=FALSE)
sample_values_2 <- sample(pop_values[strata==1],size=sample_size/2,replace=FALSE)
sample_values <- c(sample_values_1,sample_values_2)
storemean[iter] <- mean(sample_values)
sample_values_SRS <- sample(pop_values,size=sample_size,replace=FALSE)
storeSRSmean[iter] <- mean(sample_values_SRS)
}
# compare the two sampling distributions to assess the precision gain associated with stratified sampling
# First, look at the sampling distribution of stratified random sampling
mean(storemean)  # the average estimate is unbiased and therefore should be close to the true population mean
sd(storemean) # If numiter were infinite, this would be the true standard error of the sampling distribution
plot(density(storemean)) # becomes approximately normal as sample_size increases
# visually compare the sampling distributions
p1 <- hist(storemean,30)
p2 <- hist(storeSRSmean,30)
plot(p1, col=rgb(0,0,1,1/4), xlim=c(4000,6000))
plot(p2, col=rgb(1,0,0,1/4), xlim=c(4000,6000), add=T)
# create a "population" from which we will draw a sample
pop_values <- seq(1,10000, by=1)
hist(pop_values,breaks=20)  # notice that the population distribution is uniform
mean(pop_values)  # calculate the mean of the population
nrow(as.matrix(pop_values))  # calculate the number of elements in the population
# calculate properties of the sampling distribution from _simple_ random sampling
# first: calculate sigma
sigma <- sqrt(sum((pop_values - mean(pop_values))^2)/nrow(as.matrix(pop_values)))  # to find the population standard deviation (divide by N, not N-1, because mean is not estimated)
sigma  # standard deviation
# determine the N
sample_size <- 100
true_SE <- sigma/sqrt(sample_size)  # true standard error under simple random sampling
true_SE
# draw a clustered random sample
cluster <- rep(1:1000,each=10)  # define clusters
clustvals <- sort(unique(cluster)) # create unique cluster identifiers
clustsel <- sample(clustvals,10)  # use sample command to select 10 clusters
sample_values <- pop_values[cluster %in% clustsel]  # select the cases in the sampled clusters
nrow(as.matrix(sample_values))  # verify that N=100
# how close is the sample mean to the true population mean?
mean(sample_values)
mean(pop_values)
# use a "loop" to simulate what would happen if we were to replicate our sampling procedure a large number of times
numiter <- 10000
# number of iterations - want to make this as large as possible (if you have time to wait)
storemean <- storeSRSmean <- rep(NA,numiter)  # initialize the output variables as NA values at the outset
for (iter in 1:numiter) {
cluster <- rep(1:1000,each=10)
clustvals <- sort(unique(cluster))
clustsel <- sample(clustvals,10)
sample_values <- pop_values[cluster %in% clustsel]
storemean[iter] <- mean(sample_values)
sample_values_SRS <- sample(pop_values,size=sample_size,replace=FALSE)
storeSRSmean[iter] <- mean(sample_values_SRS)
}
# compare the two sampling distributions to assess the precision loss associated with clustered sampling
summary(storemean)
summary(storeSRSmean)
# visually compare the sampling distributions
p1 <- hist(storemean,30)
p2 <- hist(storeSRSmean,30)
plot(p1, col=rgb(0,0,1,1/4), ylim=c(0,1500), xlim=c(1500,8500))
plot(p2, col=rgb(1,0,0,1/4), ylim=c(0,1500), xlim=c(1500,8500), add=T)
hist(storeSRSmean,30)
hist(storemean,30)
2+2
?mean
seth <- 100
seth
vector <- c(1,2,3,4)
vector
vector[4]
vector[c(2,3)]
vector[2,3]
numbers <- rnorm(n=100)
quantile(x=numbers,probs=.5)
numbers <- rnorm(n=100)
quantile(x=numbers,probs=.5)
numbers <- rnorm(n=100)
quantile(x=numbers,probs=.5)
numbers <- rnorm(n=100)
quantile(x=numbers,probs=.5)
Z <- rbinom(n=100,size=1,prob=.6)
Z
table(Z)
numbers[Z==1]
Z==1
mean(numbers[Z==1])
mean(numbers[Z==0])
rm(list=ls(all=TRUE))		# clear all objects in memory
4
"yes"
2+3
1039/49
46^700
(3.5+2.7)/(900*2)
1.5:10
rep(("apple","orange"),3)
rep("apple","orange"),3)
rep(c("apple","orange"),3)
x <- c(1,2,3,4)
x
x[2]
typeof(x)
stringvec <- c("one","neo","eon")
stringvec
c(stringvec, abcd)
?read.csv
install.packages(c("AER", "ri", "plyr", "lubridate",
"arm"),dependencies=TRUE)
2+2
rm(list=ls(all=TRUE))		# clear all objects in memory
4
103
2+2
rm(list=ls(all=TRUE))		# clear all objects in memory
#####################################
# R Code - Rosenbaum confidence intervals.R
# POLS 4368 - Experiments
# 19 Feb 2013
#####################################
# Install RI package
# install.packages("ri", dependencies=TRUE)
rm(list=ls(all=T))   # clear memory
library(ri)
ntreat <- 500
ncontrol <- 3500
N <- ntreat+ncontrol
# ratio of treatment to control standard deviations
ratio <- 2
Y0 <- rnorm(N)
Y0 <- Y0 - mean(Y0)
Y1 <- rnorm(N)*ratio
Y1 <- Y1 - mean(Y1)
# True ATE is Zero.
Z <- c(rep(1,ntreat),rep(0,ncontrol))
perms <- genperms(Z,maxiter=500)
upperci <- lowerci <- rep(NA,ncol(perms))
Nupperci <- Nlowerci <- rep(NA,ncol(perms))
Pupperci <- Plowerci <- rep(NA,ncol(perms))
for (i in 1:ncol(perms)) {
Zri <- perms[,i]
Y <- Y0*(1-Zri) + Y1*Zri
upperci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.975)
lowerci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.025)
seest <- (var(Y[Zri==1])/sum(Zri) + var(Y[Zri==0])/sum(1-Zri))^.5
ateest <- mean(Y[Zri==1]) - mean(Y[Zri==0])
Nupperci[i] <- ateest + 1.96*seest
Nlowerci[i] <- ateest - 1.96*seest
Ys <- genouts(Y,Zri,ate=ateest)
cis <- quantile(gendist(Ys,perms,prob=rep(mean(Zri),N)),c(0.025,0.975))
Plowerci[i] <- cis[1]
Pupperci[i] <- cis[2]
cat(i,"")
}
#####################################
# R Code - Rosenbaum confidence intervals.R
# POLS 4368 - Experiments
# 19 Feb 2013
#####################################
# Install RI package
# install.packages("ri", dependencies=TRUE)
rm(list=ls(all=T))   # clear memory
library(ri)
#####################################
# the invert.ci() function in the RI package
# Experimental code to generate endpoints of Rosenbaum (2002)-style
# confidence intervals through inversion of a constant effects hypothesis.
# Only conducts inference with the difference in (weighted) means
# as the test statistic, no covariate adjustment
# Intuition behind method:
# 1) Take Y1, subtract posited ATE
# 2) Test statistical significance between actual Y0s and
#    synthetic Y0s manufactured in the treatment group
# 3) Repeat (1) and (2) for a bunch of posited ATEs, for each
#	 test the null (mean synthetic Y0s = mean actual Y0s)
# Note: if you overshoot you start to strain credulity
# the invert.ci() function:
#   Input arguments:
#	Y - numeric vector of length N, outcome variable
#	Z - binary vector (0 or 1) of length N, treatment indicator
#	prob - numeric vector within the (0,1) interval of length N,
#		probability of treatment assignment, as outputted by genprob() or genprobexact().
#		When prob=NULL (the default), assumes uniform probability of assignment
#		to treatment equal to the mean of Z
#	perms - N-by-r permutation matrix, as output by genperms or genperms.custom
#	targetp - target p-value for the endpoint of the confidence interval
#####################################
# Example: from Rosenbaum example.R in "Data and R Programs" on Courseworks
# Generate some data
ntreat <- 50
ncontrol <- 350
N <- ntreat+ncontrol
# ratio of treatment to control standard deviations
ratio <- 2
Y0 <- rnorm(N)
Y0 <- Y0 - mean(Y0)
Y1 <- rnorm(N)*ratio
Y1 <- Y1 - mean(Y1)
# True ATE is Zero.
Z <- c(rep(1,ntreat),rep(0,ncontrol))
perms <- genperms(Z,maxiter=500)
upperci <- lowerci <- rep(NA,ncol(perms))
Nupperci <- Nlowerci <- rep(NA,ncol(perms))
Pupperci <- Plowerci <- rep(NA,ncol(perms))
for (i in 1:ncol(perms)) {
Zri <- perms[,i]
Y <- Y0*(1-Zri) + Y1*Zri
upperci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.975)
lowerci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.025)
seest <- (var(Y[Zri==1])/sum(Zri) + var(Y[Zri==0])/sum(1-Zri))^.5
ateest <- mean(Y[Zri==1]) - mean(Y[Zri==0])
Nupperci[i] <- ateest + 1.96*seest
Nlowerci[i] <- ateest - 1.96*seest
Ys <- genouts(Y,Zri,ate=ateest)
cis <- quantile(gendist(Ys,perms,prob=rep(mean(Zri),N)),c(0.025,0.975))
Plowerci[i] <- cis[1]
Pupperci[i] <- cis[2]
cat(i,"")
}
# Coverage of Neyman + normal approx
mean(Nupperci >= 0 & Nlowerci <= 0,na.rm=TRUE)
# Coverage of Rosenbaum method
mean(upperci >= 0 & lowerci <= 0,na.rm=TRUE)
# Coverage of Aronow method
mean(Pupperci >= 0 & Plowerci <= 0,na.rm=TRUE)
# Summarizing intervals
summary(Nupperci)
summary(upperci)
summary(Pupperci)
summary(Nlowerci)
summary(lowerci)
summary(Plowerci)
#####################################
# R Code - Rosenbaum confidence intervals.R
# POLS 4368 - Experiments
# 19 Feb 2013
#####################################
# Install RI package
# install.packages("ri", dependencies=TRUE)
rm(list=ls(all=T))   # clear memory
library(ri)
#####################################
# the invert.ci() function in the RI package
# Experimental code to generate endpoints of Rosenbaum (2002)-style
# confidence intervals through inversion of a constant effects hypothesis.
# Only conducts inference with the difference in (weighted) means
# as the test statistic, no covariate adjustment
# Intuition behind method:
# 1) Take Y1, subtract posited ATE
# 2) Test statistical significance between actual Y0s and
#    synthetic Y0s manufactured in the treatment group
# 3) Repeat (1) and (2) for a bunch of posited ATEs, for each
#	 test the null (mean synthetic Y0s = mean actual Y0s)
# Note: if you overshoot you start to strain credulity
# the invert.ci() function:
#   Input arguments:
#	Y - numeric vector of length N, outcome variable
#	Z - binary vector (0 or 1) of length N, treatment indicator
#	prob - numeric vector within the (0,1) interval of length N,
#		probability of treatment assignment, as outputted by genprob() or genprobexact().
#		When prob=NULL (the default), assumes uniform probability of assignment
#		to treatment equal to the mean of Z
#	perms - N-by-r permutation matrix, as output by genperms or genperms.custom
#	targetp - target p-value for the endpoint of the confidence interval
#####################################
# Example: from Rosenbaum example.R in "Data and R Programs" on Courseworks
# Generate some data
ntreat <- 350
ncontrol <- 50
N <- ntreat+ncontrol
# ratio of treatment to control standard deviations
ratio <- 2
Y0 <- rnorm(N)
Y0 <- Y0 - mean(Y0)
Y1 <- rnorm(N)*ratio
Y1 <- Y1 - mean(Y1)
# True ATE is Zero.
Z <- c(rep(1,ntreat),rep(0,ncontrol))
perms <- genperms(Z,maxiter=500)
upperci <- lowerci <- rep(NA,ncol(perms))
Nupperci <- Nlowerci <- rep(NA,ncol(perms))
Pupperci <- Plowerci <- rep(NA,ncol(perms))
for (i in 1:ncol(perms)) {
Zri <- perms[,i]
Y <- Y0*(1-Zri) + Y1*Zri
upperci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.975)
lowerci[i] <- invert.ci(Y,Zri,prob=rep(mean(Zri),N),perms=perms,targetp=0.025)
seest <- (var(Y[Zri==1])/sum(Zri) + var(Y[Zri==0])/sum(1-Zri))^.5
ateest <- mean(Y[Zri==1]) - mean(Y[Zri==0])
Nupperci[i] <- ateest + 1.96*seest
Nlowerci[i] <- ateest - 1.96*seest
Ys <- genouts(Y,Zri,ate=ateest)
cis <- quantile(gendist(Ys,perms,prob=rep(mean(Zri),N)),c(0.025,0.975))
Plowerci[i] <- cis[1]
Pupperci[i] <- cis[2]
cat(i,"")
}
# Coverage of Neyman + normal approx
mean(Nupperci >= 0 & Nlowerci <= 0,na.rm=TRUE)
# Coverage of Rosenbaum method
mean(upperci >= 0 & lowerci <= 0,na.rm=TRUE)
# Coverage of Aronow method
mean(Pupperci >= 0 & Plowerci <= 0,na.rm=TRUE)
# Summarizing intervals
summary(Nupperci)
summary(upperci)
summary(Pupperci)
summary(Nlowerci)
summary(lowerci)
summary(Plowerci)
setwd("~/Dropbox/Teaching 2015-2016/Experiments/Data and R Programs/Chapter 6")
rm(list=ls(all=TRUE))
# note first must set file directory where data file is stored
# example for mac: setwd("/Users/name/Documents/Data/")
# example for windows: setwd("C:/Documents/Data/") or setwd("C:\\Documents\\Data\\")
# if not sure of working directory, type: getwd()
#Load Relevant packages (Note that when you download sem, you will also have to download matrixcalc.)
library(foreign)
library(sem)
library(aer)
install.packages("aer")
Y
library(AER)
install.packages("AER")
hajjdata <- read.dta("Chapter 6_Clingingsmith, Khwaja, and Kremer (2009) Dataset.dta")
attach(hajjdata)
hajjdata <- as.data.frame(hajjdata)
head(hajjdata)
Z <- hajjdata$success
D <- hajjdata$hajj2006
Y <- hajjdata$views
out.lm <- lm(D ~ Z)
summary(out.lm)
coefftest(out.lm,vcovHC(out.lm))
install.packages("sandwich")
library(sandwich)
out.lm <- lm(D ~ Z)
coefftest(out.lm,vcovHC(out.lm))
coeftest(out.lm,vcovHC(out.lm))
#Clear any previous work
rm(list=ls(all=TRUE))
#Load Relevant packages
library(AER)
library(sandwich)
data1 <- read.csv(file="http://hdl.handle.net/10079/70rxwqn",head=TRUE,sep=",")
sel <-  data1$onetreat==1 & data1$mailings==0 & data1$phongotv==0 & data1$persons==1
# verify the number of observations
table(sel)
data2 <- data1[sel,]
v98      <- data2$v98
persngrp <- data2$persngrp
cntany   <- data2$cntany
coef(summary(lm(v98 ~ persngrp)))
itt_fit <- lm(v98 ~ persngrp)
coeftest(itt_fit,vcovHC(itt_fit))
rm(list=ls(all=TRUE))
# note first must set file directory where data file is stored
# example for mac: setwd("/Users/name/Documents/Data/")
# example for windows: setwd("C:/Documents/Data/") or setwd("C:\\Documents\\Data\\")
# if not sure of working directory, type: getwd()
#Load Relevant packages (Note that when you download sem, you will also have to download matrixcalc.)
library(foreign)
library(AER)
library(sandwich)
# Import Data
hajjdata <- read.dta("Chapter 6_Clingingsmith, Khwaja, and Kremer (2009) Dataset.dta")
attach(hajjdata)
hajjdata <- as.data.frame(hajjdata)
head(hajjdata)
# Rename Variables
Z <- hajjdata$success
D <- hajjdata$hajj2006
Y <- hajjdata$views
coef(summary(lm(Y ~ Z)))
itt_fit <- lm(Y ~ Z)
coeftest(itt_fit,vcovHC(itt_fit))
# Regression Estimate of the ITT_D
coef(summary(lm(D ~ Z)))
# robust SEs
ittD_fit <- lm(D ~ Z)
coeftest(ittD_fit,vcovHC(ittD_fit))
coef(summary(tsls(Y ~ Z),~Z))
coef(summary(ivreg(Y ~ D),~Z))
coef(summary(ivreg(Y ~ D,~Z)))
coef(summary(ivreg(Y ~ D,~Z)))
# robust SEs
cace_fit <- ivreg(Y ~ D,~Z)
coeftest(cace_fit,vcovHC(cace_fit))
coef(summary(ivreg(Y ~ D),~Z)))
coef(summary(ivreg(Y ~ D,~Z)))
mean(Y[Z==0])
mean(Y[Z==1])
mean(Y[Z==1])-mean(Y[Z==0])
mean(Y[Z==0])
mean(Y[Z==1])
mean(Y[Z==1])-mean(Y[Z==0])  # ITT
install.packages("gmodels")
library(gmodels)    # package creates crosstabs
CrossTable(Y,Z,prop.r=F,prop.t=F,prop.chisq=F,format="SPSS")
# View ITT_D as a crosstab
CrossTable(D,Z,prop.r=F,prop.t=F,prop.chisq=F,format="SPSS")
# Regression Estimate of the ITT_D
coef(summary(lm(D ~ Z)))
# robust SEs
ittD_fit <- lm(D ~ Z)
coeftest(ittD_fit,vcovHC(ittD_fit))
# Compare means to get ITT
mean(Y[Z==0])
mean(Y[Z==1])
mean(Y[Z==1])-mean(Y[Z==0])  # ITT
# Regression Estimate of the ITT
coef(summary(lm(Y ~ Z)))
# robust SEs
itt_fit <- lm(Y ~ Z)
coeftest(itt_fit,vcovHC(itt_fit))
# 2SLS Regression Estimate of CACE
coef(summary(ivreg(Y ~ D,~Z)))
# robust SEs
cace_fit <- ivreg(Y ~ D,~Z)
coeftest(cace_fit,vcovHC(cace_fit))
# Exercise 6.10 (Election monitoring experiment)
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
library(foreign)    # package allows R to read Stata datasets
# Data are from Hyde, Susan. 2010. “Experimenting in Democracy Promotion: International Observers and the 2004 Presidential Elections in Indonesia.” Perspectives on Politics 8:511-27.
hyde <- read.dta("Chapter 6_Hyde (2010) Dataset.dta")
Z <- as.integer(hyde$Sample) -1   # monitoring treatment
Y <- hyde$invalidballots
probs <- genprobexact(Z)          # generate probability of treatment assignment
ate <- estate(Y,Z,prob=probs)     # estimate the ITT (ATE of assignment)
perms <- genperms(Z,maxiter=10000)  # set the number of simulated random assignments
Ys <- genouts(Y,Z,ate=0)       # create potential outcomes under the sharp null of no effect for any unit
distout <- gendist(Ys,perms,prob=probs)  # generate the sampling distribution  based on the schedule of potential outcomes implied by the null hypothesis
ate
View(hyde)
4.82/0.8163
ate                             # report the estimated ITT (ATE of assignment)
sum(distout >= ate)
sum(abs(distout) >= abs(ate))
dispdist(distout,ate)       # display p-values, 95% confidence interval, standard error under the null, and graph the sampling distribution under the null
