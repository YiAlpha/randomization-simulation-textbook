vars1 <- gss[, c("sex", "educ", "marriage")]
cap1 <- "summary"
tableNominal(vars = vars1, cap = cap1, vertical = FALSE, lab =
+ "tab: nominal1", longtable = FALSE)
tableNominal(vars = vars1, cap = cap1, vertical = FALSE,
lab ="tab: nominal1", longtable = FALSE)
vars3 <- gss[, c("lg_hinc", "age", "pinc_10k")]
cap3 <- "data summary."
vars3 <- gss[, c("lg_hinc", "age", "pinc_10k")]
cap3 <- "data summary."
tableDate(vars = vars3, stats =c("n", "min", "max", "na"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
tableDate(vars = vars3, stats =c("n", "min", "q1", "median", "mean", "q3", "max",
"s", "iqr","na"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
tableDate(vars = vars3, stats =c("n", "min", "q1", "median", "mean", "q3", "max",
"s", "iqr","na"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
tableDate(vars = vars3, stats =c("n", "min", "median", "mean",  "max", "s","na"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
tableDate(vars = vars3, stats =c("n", "min", "median", "mean",  "max","na"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
rm(attr(gss$age, "format.stata"))
attr(gss$age, "format.stata") < NA
attr(gss$age, "format.stata") <- NA
remove(attr(gss$age, "format.stata"))
vars3 <- gss[, c("lg_hinc", "pinc_10k")]
cap3 <- "data summary."
tableDate(vars = vars3, stats =c("n", "min", "median", "mean",  "max","na" "s"),
tableDate(vars = vars3, stats =c("n", "min", "median", "mean",  "max","na","s"),
cap = cap3, lab ="tab: data1", longtable = FALSE)
stargazer::stargazer(gss, type = 'text')
vars1 <- gss[, -c("stereotype", "age", "lg_hinc","lg_pwinc",
"hinc_10k","pinc_10k","pwinc_10k")]
vars1 <- gss%>%select(-("stereotype", "age", "lg_hinc","lg_pwinc",
vars1 <- gss[, -c("stereotype", "age", "lg_hinc","lg_pwinc",
"hinc_10k","pinc_10k")]
vars1 <- gss[, c("educ", "sex", "internet_use","eng_listen",
"eng_speak","marriage")]
cap1 <- "summary"
tableNominal(vars = vars1, cap = cap1, vertical = FALSE,
lab ="tab: nominal1", longtable = FALSE)
stargazer::stargazer(gss)
table(gss$stereotype)
gss <- gss%>%mutate(stereo = ifelse(stereotype>0, stereotype, NA))%>%
stargazer::stargazer(gss)
cgss <- data%>%
select(a421, # dependent
a69,a7a,a2 ,a62 ,a8a ,a8b ,
a285,a51 ,a52, a301, a302, a303)%>%
mutate(age = 2015 -a301)%>% # recode to age
mutate(stereotype = ifelse(a421>0, a421, NA))%>%
mutate(educ = case_when( # recode to the education
is.na(a7a) ~ NA_real_,
a7a ==1 ~ 1,
a7a>1 & a7a<4 ~ 2,
a7a ==4 ~ 3,
a7a>4 & a7a<9 ~ 4,
a7a>9 & a7a<14 ~ 5,
TRUE ~ NA_real_))%>%
mutate(educ = as.factor(educ))%>%
mutate(sex = as.factor(a2))
levels(cgss$educ) <- c('no_educ','elementary','middle_sch','high_sch','uni_above')
levels(cgss$sex) <- c('male', 'female')
# log the income
cgss <-cgss%>%mutate(lg_hinc = case_when(a62 < 0 ~ NA_real_,
a62 ==0 ~ 0,
a62 >0 ~ log(as.numeric(a62))))%>%
mutate(lg_pinc = case_when(a8a < 0 ~ NA_real_,
a8a ==0 ~ 0,
a8a >0 ~ log(as.numeric(a8a))))%>%
mutate(lg_pwinc = case_when(a8b < 0 ~ NA_real_,
a8b ==0 ~ 0,
a8b >0 ~ log(as.numeric(a8b))))
# code the personal variables
cgss <-cgss%>%mutate(internet_use = ifelse(a285>0, a285, NA))
cgss$internet_use <- as.factor(cgss$internet_use)
levels(cgss$internet_use) <-c('never', 'seldom', 'sometimes', 'often', 'very often')
cgss <-cgss%>%mutate(eng_listen = ifelse(a51>0, a51, NA))
cgss$eng_listen <- as.factor(cgss$eng_listen)
levels(cgss$eng_listen) <-c('not understand', 'poor', 'so so', 'fair', 'very good')
cgss <-cgss%>%mutate(eng_speak = ifelse(a52>0, a52, NA))
cgss$eng_speak <- as.factor(cgss$eng_speak)
levels(cgss$eng_speak) <-c('not understand', 'poor', 'so so', 'fair', 'very good')
cgss <-cgss%>%mutate(marriage = ifelse(a69>0, a69, NA))
cgss$marriage <- as.factor(cgss$marriage)
levels(cgss$marriage) <-c('unmarried', 'cohabiting', 'married_1st', 'remarried',
'seperating', 'divorced', 'widowed')
cgss <-cgss%>%mutate(hinc_10k = case_when(a62 < 0 ~ NA_real_,
a62 ==0 ~ 0,
a62 >0 ~ as.numeric(a62)/10000))%>%
mutate(pinc_10k = case_when(a8a < 0 ~ NA_real_,
a8a ==0 ~ 0,
a8a >0 ~ as.numeric(a8a)/10000))%>%
mutate(pwinc_10k = case_when(a8b < 0 ~ NA_real_,
a8b ==0 ~ 0,
a8b >0 ~ as.numeric(a8b)/10000))
gss <- cgss %>%
select(-c(a69,a7a,a2 ,a62 ,a8a ,a8b ,
a285,a51 ,a52, a301, a302, a303))%>%
sjlabelled::remove_all_labels()
gss <- cgss %>%
select(-c(a421,a69,a7a,a2 ,a62 ,a8a ,a8b ,
a285,a51 ,a52, a301, a302, a303))%>%
sjlabelled::remove_all_labels()
stargazer::stargazer(gss)
rm(list = ls())
Y <- c(rep(1, 38), rep(0, 542-38), rep(1, 55), rep(0, 542-55),
rep(1, 46), rep(0, 541-46), rep(1, 71), rep(0, 541-71),
rep(1, 37), rep(0, 670-37), rep(1, 48), rep(0, 670-48),
rep(1, 36), rep(0, 682-36), rep(1, 61), rep(0, 682-61))
boston <- c(rep(1, 542+542+541+541), rep(0, 670+670+682+682))
chicago <- 1-boston
lowquality <- c(rep(1, 542+542), rep(0, 541+541), rep(1, 670+670), rep(0, 682+682))
highquality <- 1-lowquality
black<- c(rep(1, 542), rep(0,542), rep(1, 541), rep(0,541),
rep(1, 670), rep(0,670), rep(1, 682), rep(0,682))
white <- 1-black
fit_1 <- lm(Y ~ white + highquality + chicago + white*highquality +
white*chicago + highquality*chicago + white*highquality*chicago)
fit_2 <- lm(Y ~ black + highquality + chicago + black*highquality +
black*chicago + highquality*chicago + black*highquality*chicago)
fit_3 <- lm(Y ~ white + highquality + boston + white*highquality +
white*boston + highquality*boston + white*highquality*boston)
fit_4 <- lm(Y ~ black + lowquality + chicago + black*lowquality +
black*chicago + lowquality*chicago + black*lowquality*chicago)
stargazer::stargazer(fit_1, fit_2, fit_3, fit_4, style = "apsr", type = "text")
rm(list = ls())
remove.packages(raw)
#Clear any previous work
rm(list=ls(all=TRUE))
#Load Relevant packages
library(foreign)
#Read in Data from Internet
bedout <- read.dta("http://hdl.handle.net/10079/xksn0db")
bedout
library(ri)
?genperms
genperms
lm1$coefficients
rm(list = ls())
combn
?combn
combn(letters[1:4], 2)
combn(letters[1:4], 4)
combn(c(1,1,1,1,2,2,2,3,3,4), 3, tabulate, nbins = 4)
rm(list = ls())
remove.packages("rmdformats")
rm(list = ls())
install.packages('rmdformats')
rm(list=ls())       # clear objects in memory
library(ri)
# schedule of potential outcomes for problem 10.3
Z <- c(0,0,0,0,0,0,1,1,1,1,1,1)
Y0M0 = c(0,0,0,0,0,0,1,1,1,0,0,0)
Y1M0 = c(0,0,0,1,1,1,0,0,0,1,1,1)
Y0M1 = c(0,0,0,0,0,0,1,1,1,1,1,1)
Y1M1 = c(0,0,0,1,1,1,1,1,1,1,1,1)
M0 = c(0,0,1,0,0,1,0,0,1,0,0,1)
M1 = c(0,1,1,0,1,1,0,1,1,0,1,1)
# verify column averages
mean(Y0M0)
mean(Y1M0)
mean(Y0M1)
mean(Y1M1)
# simulate all possible random assignments
perms <- genperms(Z)
?genperms
genperms
combn
coefmat <- matrix(NA,ncol(perms),3)  # stores estimates from equation 10.3
tcoefmat <- matrix(NA,ncol(perms),2) # stores estimates from equation 10.2
mcoefmat <- matrix(NA,ncol(perms),2) # stores estimates from equation 10.1
for (i in 1:ncol(perms)) {
Zri <- perms[,i]
M <- M0*(1-Zri) + M1*Zri
Y <- Y0M0*(1-Zri)*(1-M) + Y1M0*(Zri)*(1-M) + Y0M1*(1-Zri)*(M) + Y1M1*(Zri)*(M)
coefmat[i,] <- lm(Y~M+Zri)$coefficients
tcoefmat[i,] <- lm(Y~Zri)$coefficients
mcoefmat[i,] <- lm(M~Zri)$coefficients
}
# results omit instances of perfect colinearity between M and Z
colMeans(na.omit(coefmat))  # report the avg coefficients from a regression of Y on M and Z
colMeans(na.omit(tcoefmat)) # report the avg coefficients from a regression of Y on Z
colMeans(na.omit(mcoefmat)) # report the avg coefficients from a regression of M on Z
View(coefmat)
View(coefmat)
colMeans(coefmat)
nona <- na.omit(coefmat)
View(nona)
coefmat[1:10,]
nona[1:10,]
rm(nona)
na.omit
is.na(coefmat)
library(tidyverse)
df <-as.tibble(coefmat)
na.omit(df)
df <-mutate(df, id = row_number())
dfno <- na.omit(df)
no <- anti_join(df, dfno)
View(no)
no$id
df <-as.tibble(tcoefmat)
df <-mutate(df, id = row_number())
dfno <- na.omit(df)
no <- anti_join(df, dfno)
df <-as.tibble(mcoefmat)
df <-mutate(df, id = row_number())
dfno <- na.omit(df)
View(mcoefmat)
colMeans(na.omit(mcoefmat))
df <-as.tibble(mcoefmat)
df <-mutate(df, id = row_number())
dfno <- na.omit(df)
mean(df$V1)
mean(df$V2)
View(tcoefmat)
View(coefmat)
View(mcoefmat)
head(df)
head(mcoefmat)
rm(list=ls())       # clear objects in memory
library(ri)
# schedule of potential outcomes for problem 10.3
Z <- c(0,0,0,0,0,0,1,1,1,1,1,1)
Y0M0 = c(0,0,0,0,0,0,1,1,1,0,0,0)
Y1M0 = c(0,0,0,1,1,1,0,0,0,1,1,1)
Y0M1 = c(0,0,0,0,0,0,1,1,1,1,1,1)
Y1M1 = c(0,0,0,1,1,1,1,1,1,1,1,1)
M0 = c(0,0,1,0,0,1,0,0,1,0,0,1)
M1 = c(0,1,1,0,1,1,0,1,1,0,1,1)
# verify column averages
mean(Y0M0)
mean(Y1M0)
mean(Y0M1)
mean(Y1M1)
# simulate all possible random assignments
perms <- genperms(Z)
coefmat <- matrix(NA,ncol(perms),3)  # stores estimates from equation 10.3
tcoefmat <- matrix(NA,ncol(perms),2) # stores estimates from equation 10.2
mcoefmat <- matrix(NA,ncol(perms),2) # stores estimates from equation 10.1
for (i in 1:ncol(perms)) {
Zri <- perms[,i]
M <- M0*(1-Zri) + M1*Zri
Y <- Y0M0*(1-Zri)*(1-M) + Y1M0*(Zri)*(1-M) + Y0M1*(1-Zri)*(M) + Y1M1*(Zri)*(M)
coefmat[i,] <- lm(Y~M+Zri)$coefficients
tcoefmat[i,] <- lm(Y~Zri)$coefficients
mcoefmat[i,] <- lm(M~Zri)$coefficients
}
mean(is.na(coefmat))
libary(tidyverse)
library(tidyverse)
cm <- as_tibble(coefmat)%>%mutate(id=row_number())
cm_omitna <- as_tibble(coefmat)%>%mutate(id=row_number())%>%drop_na()
cm_na <-anti_join(cm, cm_omitna)
perms[,cm_na$id]
cm_na$id
perms[,530]
perms[,1]
perms[,150]
dim(na.omit(coefmat))
dim(na.omit(tcoefmat))
dim(na.omit(mcoefmat))
lm(Y~M+perms[,530])
summary(lm(Y~M+perms[,530]))
cm_na$id
M530 <- M0*(1-perms[,530]) + M1*perms[,530]
Y530 <- Y0M0*(1-perms[,530])*(1-M) + Y1M0*(perms[,530])*(1-M) + Y0M1*(1-perms[,530])*(M) + Y1M1*(perms[,530])*(M)
summary(lm(Y530~M530+perms[,530]))
Z <-  titiunik$term2year       # treatment is 2 year rather than 4 year term
Y <- titiunik$bills_introduced
block <- titiunik$texas0_arkansas1   # randomization occurs within each state
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 3")
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
setwd("/Users/donaldgreen/Dropbox/Field Experimentation Book/Final Code for Vignettes and Problems/Chapter 3/")
library(foreign)    # package allows R to read Stata datasets
titiunik <- read.dta("Titiunik data for Exercises to Chapter 3.dta")
Z <-  titiunik$term2year       # treatment is 2 year rather than 4 year term
Y <- titiunik$bills_introduced
block <- titiunik$texas0_arkansas1   # randomization occurs within each state
probs <- genprobexact(Z,blockvar=block)   # blocking is assumed when generating probability of treatment
table(probs)
gendist
estate
mean(Y[Z==1 & block==0])
mean(Y[Z==0 & block==0])
mean(Y[Z==1 & block==1])
mean(Y[Z==0 & block==1])
mean(block==0)
mean(block==1)
# put the formula together to create a block-by-block weighted avg
mean(block==0)*(mean(Y[Z==1 & block==0])-mean(Y[Z==0 & block==0])) + mean(block==1)*(mean(Y[Z==1 & block==1])-mean(Y[Z==0 & block==1]))
# generate IPW weights
ipw <- (1-block)*(Z/mean(Z[block==0]) + (1-Z)/(1-mean(Z[block==0]))) +
(block)  *(Z/mean(Z[block==1]) + (1-Z)/(1-mean(Z[block==1])))
ipw
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 3")
library(foreign)    # package allows R to read Stata datasets
titiunik <- read.dta("Titiunik data for Exercises to Chapter 3.dta")
Z <-  titiunik$term2year       # treatment is 2 year rather than 4 year term
Y <- titiunik$bills_introduced
block <- titiunik$texas0_arkansas1   # randomization occurs within each state
probs <- genprobexact(Z,blockvar=block)   # blocking is assumed when generating probability of treatment
table(probs)
ate <- estate(Y,Z,prob=probs)      # estimate the ATE
perms <- genperms(Z,maxiter=10000,blockvar=block)   # set the number of simulated random assignments
Ys <- genouts(Y,Z,ate=0)    # create potential outcomes under the sharp null of no effect for any unit
distout <- gendist(Ys,perms,prob=probs)  # generate the sampling distribution  based on the schedule of potential outcomes implied by the null hypothesis
ate                             # estimated ATE
mean(abs(distout) >= abs(ate))  # two-tailed comparison used to calculate p-value
dispdist(distout,ate)       # display p-values, 95% confidence interval, standard error under the null, and graph the sampling distribution under the null
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 3")
setwd("~/MA/2019Spring/RAship/FEDAI/check_code_FEIDA")
library(readstata13)
stata_perm <-read.dta13("(3_8_resam.dta")
stata_perm <-read.dta13("3_8_resam.dta")
library(tidyverse)
stata_perm <-stata_perm%>%select(starts_with("D"))
stata_perm <-stata_perm%>%select(starts_with("D"))%>%select(-D)
distout <- gendist(Ys,stata_perm,prob=probs)  # generate the sampling distribution  based on the schedule of potential outcomes implied by the null hypothesis
ate                             # estimated ATE
mean(abs(distout) >= abs(ate))  # two-tailed comparison used to calculate p-value
dispdist(distout,ate)
######
### check stata perms
######
setwd("~/MA/2019Spring/RAship/FEDAI/check_code_FEIDA")
library(readstata13)
stata_perm <-read.dta13("3_8_resam.dta")
stata_perm <-read.dta13("3_8_resam.dta")
rm(stata_perm)
library(readstata13)
stata_perm <-read.dta13("3_8_resam.dta")
library(tidyverse)
stata_perm <-stata_perm%>%select(starts_with("D"))%>%select(-D)
stata_perm <-stata_perm%>%select(starts_with("D"))%>%select(-D)
######
### check stata perms
######
setwd("~/MA/2019Spring/RAship/FEDAI/check_code_FEIDA")
library(readstata13)
stata_perm <-read.dta13("3_8_resam.dta")
library(tidyverse)
stata_perm <-stata_perm%>%select(starts_with("D"))%>%select(-D)
distout <- gendist(Ys,stata_perm,prob=probs)  # generate the sampling distribution  based on the schedule of potential outcomes implied by the null hypothesis
ate                             # estimated ATE
mean(abs(distout) >= abs(ate))  # two-tailed comparison used to calculate p-value
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 3")
library(foreign)    # package allows R to read Stata datasets
camerer <- read.dta("Camerer data for Chapter 3 exercises.dta")
colnames(camerer)
Z <-  camerer$treatment
Y <- camerer$experimentbets
block <- camerer$pair        # indicates how the subjects are blocked
covs <- as.matrix(camerer$preexperimentbets)     # reads in covariates
probs <- genprobexact(Z,blockvar=block)
colnames(camerer)
Z <-  camerer$treatment
Y <- camerer$experimentbets
block <- camerer$pair        # indicates how the subjects are blocked
covs <- as.matrix(camerer$preexperimentbets)     # reads in covariates
probs <- genprobexact(Z,blockvar=block)
numiter <- 1000
perms <- genperms(Z,maxiter=numiter,blockvar=block)
numiter <- ncol(perms)  # reset numiter so that it is no larger than the maximum number of possible randomizations
Fstat <- summary(lm(Z~covs))$fstatistic[1]   # F-statistic from actual data
Fstatstore <- rep(NA,numiter)
for (i in 1:numiter) {
Fstatstore[i] <- summary(lm(perms[,i]~covs))$fstatistic[1]  # F-statistic under the null of random assignment of Z
}
mean(Fstatstore >= Fstat)                     # p-value
probs <- genprobexact(Z,blockvar=block)    # notice the use of block to indicate how the random assignment was conducted
ate <- estate(Y,Z,prob=probs)
ate
genprobexact
estate
ate
change <- camerer$experimentbets
change_treatment <- mean(change[D==1])
change_treatment <- mean(change[Z==1])
change_treatment
change_control <- mean(change[Z==0])
change_control
ATE <- change_treatment - change_control
ATE
rm(list = ls())
Y0 <- c(0,1,2,4,4,6,6,9,14,15,16,16,17,18)
Y1 <- c(0,0,1,2,0,0,2,3,12,9,8,15,5,17)
cluster <- rep(1:7, each=2)
cluster
Ybar0 <- tapply(X=Y0, INDEX=cluster, FUN=mean)
Ybar1 <- tapply(X=Y1, INDEX=cluster, FUN=mean)
Ybar0
Ybar1
cov_Ybar0 <- cov.pop(Ybar0,Ybar1)
var.pop <- function(x){sum((x-mean(x))^2)/(length(x))}
cov.pop <- function(x,y){sum((x-mean(x))*(y-mean(y)))/(length(x))}
var_Ybar0 <- var.pop(Ybar0)
var_Ybar1 <- var.pop(Ybar1)
cov_Ybar0 <- cov.pop(Ybar0,Ybar1)
var_Ybar0
var_Ybar1
cov_Ybar0
var(Ybar0)
var
mean(Ybar0)
var_Ybar0
var_Ybar1
cov_Ybar0
se_ate
se_ate <- sqrt((1/6) * ((4/3)*var_Ybar0 + (3/4)*var_Ybar1 + 2*cov_Ybar0))
se_ate
#   -----------------------------------------------------------------------
#    Exercise 4.2 (Game-playing experiment)
#   -----------------------------------------------------------------------
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
library(foreign)    # package allows R to read Stata datasets
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 4")
rush <- read.dta("RushHour data for exercise 4-2.dta")
#   -----------------------------------------------------------------------
#    (a)
#   -----------------------------------------------------------------------
Z <- rush$treat       # treatment is thinking strategies curriculum
Y <- rush$posttest    # number of puzzled solved during the testing session
X <- rush$pretest
covs <- as.matrix(rush$pretest)     # covariate is the pretest score
probs <- genprobexact(Z)
numiter <- 50000   # set the number of simulated random assignments (if you set it to 48620 or higher, your results will be exact because that is the true number of possible random assignments)
perms <- genperms(Z,maxiter=numiter)
numiter <- ncol(perms)  # reset numiter so that it is no larger than the maximum number of possible randomizations
Fstat <- summary(lm(Z~covs))$fstatistic[1]  # observed F statistic
Fstat
Fstatstore <- rep(NA,numiter)    # initialize vector of simulated F statistics
for (i in 1:numiter) {
Fstatstore[i] <- summary(lm(perms[,i]~covs))$fstatistic[1]
}
Fstat
mean(Fstatstore >= Fstat)    # calculate p-value
sum(Fstatstore >= Fstat)
Fstatstore[1:10]
setwd("~/MA/2019Spring/RAship/FEDAI/FEDAI data/Chapter 5")
rm(list=ls())       # clear objects in memory
library(ri)         # load the RI package
set.seed(1234567)   # random number seed, so that results are reproducible
library(foreign)    # package allows R to read Stata datasets
beijing.all <- read.dta("Chapter 5_Guan and Green (2006) Dataset.dta")
colnames(beijing.all)
Z <-     beijing$treat2
Y <-     beijing$turnout
clust <- beijing$dormid
probs <- genprobexact(Z,clustvar=clust)  # subjects are clustered by dorm room
# get rid of a couple of observations with missing outcome data
beijing <- na.omit(beijing.all)
Z <-     beijing$treat2
Y <-     beijing$turnout
clust <- beijing$dormid
probs <- genprobexact(Z,clustvar=clust)  # subjects are clustered by dorm room
probs
table(probs)
rm(list=ls())
condition <- c(rep("No Mail", 2586), rep("Standard", 6858),
rep("Threat", 6694), rep("Norms", 6825),
rep("Threat+Norms", 6960), rep("Fairness", 6920),
rep("Threat+Fairness", 6750))
no_mail <- as.numeric(grepl(pattern="Mail", condition))
standard <- as.numeric(grepl(pattern="Standard", condition))
threat <- as.numeric(grepl(pattern="Threat", condition))
norms <- as.numeric(grepl(pattern="Norms", condition))
fairness <- as.numeric(grepl(pattern="Fairness", condition))
Y <- c(rep(1, round(0.0158*2586)), rep(0, 2586 - round(0.0158*2586)),
rep(1, round(0.0862*6858)), rep(0, 6858 - round(0.0862*6858)),
rep(1, round(0.0967*6694)), rep(0, 6694 - round(0.0967*6694)),
rep(1, round(0.0823*6825)), rep(0, 6825 - round(0.0823*6825)),
rep(1, round(0.0970*6960)), rep(0, 6960 - round(0.0970*6960)),
rep(1, round(0.0819*6920)), rep(0, 6920 - round(0.0819*6920)),
rep(1, round(0.0932*6750)), rep(0, 6750 - round(0.0932*6750)))
fit.1 <- lm(Y~no_mail + standard + threat + norms +
fairness + threat:norms + threat:fairness - 1)
summary(fit.1)
fit.2 <- lm(Y~no_mail + standard + threat + norms +
fairness + threat:norms + threat:fairness)
summary(fit.2)
fit.1 <- lm(Y~no_mail + standard + threat + norms +
fairness + threat:norms + threat:fairness - 1)
summary(fit.1)
condition[9444]
condition[9445]
condition[16138]
condition[16139]
table(threat:fairness)
summary(fit.1)
fit.3 <- lm(Y~no_mail + standard + threat + norms +
fairness + threat:norms + threat:fairness)
summary(fit.3)
summary(no_mail)
sd(no_mail)
sd(standard )
sd(threat)
sd(norms)
sd(fairness)
sd(threat:norms)
