{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single PDF Extraction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages to read PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io (input and output); BytesIO encode string to byte object\n",
    "from io import BytesIO\n",
    "# extract all file name in a folder, for the convenience of reading PDF files\n",
    "import glob\n",
    "# re (regular expression) to find string with certain patterns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfminer to parse PDF file\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LTTextBoxHorizontal\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtation a list of all pdf file\n",
    "case_list = glob.glob('./Cases/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the PDF file you want to read\n",
    "file=case_list[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Cases/004 - Preston v Marathon Oil Co.pdf'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configure for the pdfminer package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get text from the PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout_text(file):\n",
    "    \n",
    "    #Create resource manager\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    # Set parameters for analysis.\n",
    "    laparams = LAParams()\n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    document = open(file, 'rb')\n",
    "    # each layer in a list\n",
    "    layout_text = []\n",
    "    # all the text in a string\n",
    "    raw_text = str()\n",
    "    \n",
    "    for page in PDFPage.get_pages(document):\n",
    "        interpreter.process_page(page)\n",
    "        # receive the LTPage object for the page.\n",
    "        layout = device.get_result()\n",
    "        for element in layout:\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                layout_text.append(element.get_text())\n",
    "                raw_text = raw_text.__add__(element.get_text())\n",
    "    \n",
    "    document.close()\n",
    "    device.close()\n",
    "                \n",
    "    return layout_text, raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_text, raw_text = get_layout_text(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layout_text(layout_text):\n",
    "    for i in range(len(layout_text)):\n",
    "        print('{} {} {}'.format('------------- Layer', i, \" ---------------\" ))\n",
    "        print(layout_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Layer 0  ---------------\n",
      "Preston v. Marathon Oil Co., 684 F.3d 1276 (2012)\n",
      "34 IER Cases 11, 103 U.S.P.Q.2d 1353\n",
      "\n",
      "------------- Layer 1  ---------------\n",
      "684 F.3d 1276\n",
      "\n",
      "------------- Layer 2  ---------------\n",
      "United States Court of Appeals,\n",
      "\n",
      "------------- Layer 3  ---------------\n",
      "Federal Circuit.\n",
      "\n",
      "------------- Layer 4  ---------------\n",
      "Yale PRESTON, Plaintiff–Appellant,\n",
      "\n",
      "------------- Layer 5  ---------------\n",
      "v.\n",
      "\n",
      "------------- Layer 6  ---------------\n",
      "MARATHON OIL COMPANY and Thomas Smith, Defendants–Cross Appellants,\n",
      "\n",
      "------------- Layer 7  ---------------\n",
      "and\n",
      "\n",
      "------------- Layer 8  ---------------\n",
      "John Does 1–10, Defendants.\n",
      "\n",
      "------------- Layer 9  ---------------\n",
      "Nos. 2011–1013, 2011–1026.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_layout_text(layout_text[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a dictionary contains court information\n",
    "from reporters_db import EDITIONS\n",
    "for key in list(EDITIONS.keys()):\n",
    "    EDITIONS[key.replace(\" \", \"\")]=EDITIONS[key].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression to describe citation pattern\n",
    "CITATION_PTN = r\"\"\"\n",
    "(?:[\\s,:\\(]|^)\n",
    "(\n",
    "(\\d+)\\s+\n",
    "({reporters})(\\s|[a-z])+\n",
    "(\\d+)\n",
    ")\n",
    "\"\"\".format(reporters='|'.join([re.escape(i) for i in EDITIONS]))\n",
    "CITATION_PTN_RE = re.compile(CITATION_PTN, re.IGNORECASE | re.MULTILINE | re.DOTALL | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(raw_text):\n",
    "    result = CITATION_PTN_RE.findall(raw_text)\n",
    "    citations = []\n",
    "    for cite in result:\n",
    "        the_cite = cite[0].replace(\"at \", \"\").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"\\n\", \" \")\n",
    "        if len(the_cite)<=30:\n",
    "            citations.append(the_cite)\n",
    "    # remove duplicated citations\n",
    "    citations = list(dict.fromkeys(citations))\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = get_citations(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['813 F.3d 1368',\n",
       " '2012 WL 1188903',\n",
       " '2012 WL 2838735',\n",
       " '2013 WL 6491070',\n",
       " '135 S.Ct. 831']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexnlp.extract.en.regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regulations(raw_text):\n",
    "    result =list(lexnlp.extract.en.regulations.get_regulations(raw_text, \n",
    "                                                                        return_source=False,\n",
    "                                                                        as_dict=True))\n",
    "    \n",
    "    regulations = []\n",
    "    for reg in result:\n",
    "        # sotre every regulation in the pdf file to this container\n",
    "        regulations.append(reg['regulation_code'])\n",
    "        \n",
    "    # remove duplicated regulations in a file\n",
    "    regulations = list(dict.fromkeys(regulations)) \n",
    "        \n",
    "    return  regulations   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulations = get_regulations(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28 USC § 1295']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 US patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_PATENT = r\"\"\"\n",
    "(?P<block1>[0-9]{1})[\\,]?(?P<block2>[0-9]{3})[\\,]?(?P<block3>[0-9]{3})\n",
    "\"\"\"\n",
    "RE_PATENT = re.compile(US_PATENT, re.IGNORECASE | re.UNICODE | re.DOTALL | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_patent(text, return_sources=False) -> Generator: \n",
    "    # Iterate through all potential matches\n",
    "    for match in RE_PATENT.finditer(text):\n",
    "        # Get individual group matches\n",
    "        captures = match.capturesdict()\n",
    "        patent = \"{block1},{block2},{block3}\".format(block1=captures[\"block1\"].pop(),\n",
    "                                                  block2=captures[\"block2\"].pop(),\n",
    "                                                  block3=captures[\"block3\"].pop(),\n",
    "                                                  )\n",
    "\n",
    "        if return_sources:\n",
    "            yield patent, match.group()\n",
    "        else:\n",
    "            yield patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patent(text):\n",
    "    patents =list(us_patent(text))\n",
    "    # remove duplicated patent in the list\n",
    "    result = list(dict.fromkeys(patents)) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_patent(text_layer):\n",
    "    patent_position = {}\n",
    "    for i in range(len(text_layer)):\n",
    "        # extract patent number in a pdf file, store in a list\n",
    "        text_patent =get_patent(text_layer[i])\n",
    "        # remove duplicated patent in the list\n",
    "        patent_position.update({(i,len(text_layer)): text_patent}) \n",
    "    patent_position = {i:j for i,j in patent_position.items() if j != []}\n",
    "    return patent_position\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(38, 104): ['5,737,054', '6,012,811', '6,092,896'],\n",
       " (53, 104): ['5,737,054', '6,012,811', '6,092,896'],\n",
       " (93, 104): ['6,634,227']}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position_patent(pdf_layers[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_position = {}\n",
    "for i in range(len(pdf_layers[3])):\n",
    "    # extract patent number in a pdf file, store in a list\n",
    "    text_patent =get_patent(pdf_layers[3][i])\n",
    "    # remove duplicated patent in the list\n",
    "    patent_position.update({(i,len(pdf_layers[3])): text_patent}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_position = {i:j for i,j in patent_position.items() if j != []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(38, 104): ['5,737,054', '6,012,811', '6,092,896'],\n",
       " (53, 104): ['5,737,054', '6,012,811', '6,092,896'],\n",
       " (93, 104): ['6,634,227']}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = []\n",
    "pat_li = []\n",
    "for key in list(patent_position.keys()):\n",
    "    for pat in patent_position[key]:      \n",
    "        pat_li.append(pat)\n",
    "        layer_number.append(key)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 104), (38, 104), (38, 104), (53, 104), (53, 104), (53, 104), (93, 104)]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_position_patent(text_layer):\n",
    "    patent_position = {}\n",
    "    for i in range(len(text_layer)):\n",
    "        # extract patent number in a pdf file, store in a list\n",
    "        text_patent =get_patent(text_layer[i])\n",
    "        # remove duplicated patent in the list\n",
    "        patent_position.update({(i,len(text_layer)): text_patent}) \n",
    "    patent_position = {i:j for i,j in patent_position.items() if j != []}\n",
    "    \n",
    "    layer_number = []\n",
    "    pat_li = []\n",
    "    for key in list(patent_position.keys()):\n",
    "        for pat in patent_position[key]:      \n",
    "            pat_li.append(pat)\n",
    "            layer_number.append(key)\n",
    "    return layer_number, pat_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,737,054',\n",
       " '6,012,811',\n",
       " '6,092,896',\n",
       " '5,737,054',\n",
       " '6,012,811',\n",
       " '6,092,896',\n",
       " '6,634,227']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_position_patent(pdf_layers[3])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = list(calendar.month_abbr[1:])+['Sept']+list(calendar.month_name[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression to describe citation pattern\n",
    "DATE_PTN = r\"\"\"\n",
    "(?:[\\s,:\\(]|^)\n",
    "(\n",
    "({month})(\\.*)\\s*\n",
    "(\\d+)(,)\\s*\n",
    "(\\d+)\n",
    ")\n",
    "\"\"\".format(month='|'.join([re.escape(i) for i in month_list]))\n",
    "DATE_PTN_RE = re.compile(DATE_PTN, re.IGNORECASE | re.MULTILINE | re.DOTALL | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(raw_text):\n",
    "    result = DATE_PTN_RE.findall(raw_text)\n",
    "    case_date = the_date = result[0][0].replace(\",\", \"\").replace(\"\\n\", \"\").replace(\".\", \"\")\n",
    "    \n",
    "    return case_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feb 22 2016'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write to `json` and `csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtation a list of all pdf file\n",
    "case_list = glob.glob('./Cases/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list to store the name of the pdf\n",
    "pdf_name = []\n",
    "# a list to store the content of the pdf\n",
    "pdf_layers = []\n",
    "\n",
    "pdf_text = []\n",
    "\n",
    "# a loop to read all the pdf and store their name and content to the respective list\n",
    "for case in case_list:\n",
    "    pdf_name.append(case.replace('./Cases/', '').replace('.pdf', ''))\n",
    "    layout_text, raw_text = get_layout_text(case)\n",
    "    pdf_layers.append(layout_text)\n",
    "    pdf_text.append(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw text and layers to `json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF2TEXT = '{}{}{}'.format('pdf2text',len(pdf_name), '.json' )\n",
    "# write text to a json file\n",
    "json.dump({'file_name': pdf_name,\n",
    "           'layouts': pdf_layers,\n",
    "           'raw_text': pdf_text},\n",
    "          open(PDF2TEXT, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Frequency of ciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_dict = {}\n",
    "for i in range(len(pdf_name)):\n",
    "    cite_dict[pdf_name[i]] = get_citations(pdf_text[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cite_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_df = pd.DataFrame.from_dict(cite_dict, orient='index')\n",
    "cite_df['file']= cite_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_df= pd.melt(cite_df,id_vars=['file']). \\\n",
    "            drop(['variable'], axis=1).dropna(). \\\n",
    "            rename(index=str, columns={\"value\": \"citaion\"})\n",
    "            \n",
    "# ciation_df['file'] = ciation_df['file'].str.replace('./case_test/', '')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times being cited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citaion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415 F.3d 1303</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127 S.Ct. 1727</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 L.Ed.2d 545</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167 L.Ed.2d 705</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383 U.S. 1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Times being cited\n",
       "citaion                           \n",
       "415 F.3d 1303                   33\n",
       "127 S.Ct. 1727                  20\n",
       "15 L.Ed.2d 545                  20\n",
       "167 L.Ed.2d 705                 20\n",
       "383 U.S. 1                      20"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_df.groupby(['citaion']).count().nlargest(5, 'file').\\\n",
    "rename(index=str, columns={\"file\": \"Times being cited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv file\n",
    "citation_df.to_csv(\"citation159.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Frequency of regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dict = {}\n",
    "for i in range(len(pdf_name)):\n",
    "    reg_dict[pdf_name[i]] = get_regulations(pdf_text[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dict_dropna = {i:j for i,j in reg_dict.items() if j != []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame.from_dict(reg_dict_dropna, orient='index')\n",
    "reg_df['file'] = reg_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation_df= pd.melt(reg_df,id_vars=['file']). \\\n",
    "     drop(['variable'], axis=1).dropna(). \\\n",
    "     rename(index=str, columns={\"value\": \"regulation\"})\n",
    "     \n",
    "# regulation_df['file'] = regulation_df['file'].str.replace('./case_test/', '')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times being cited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regulation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28 USC § 1295</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 103</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 112</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 271</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125 Stat. 284</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Times being cited\n",
       "regulation                      \n",
       "28 USC § 1295                119\n",
       "35 USC § 103                  30\n",
       "35 USC § 112                  26\n",
       "35 USC § 271                  20\n",
       "125 Stat. 284                 17"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulation_df.groupby(['regulation']).count().nlargest(5, 'file').\\\n",
    "rename(index=str, columns={\"file\": \"Times being cited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv file\n",
    "regulation_df.to_csv(\"regulation159.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate all the references together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_df.rename(index=str, columns={\"citaion\":\"ref\"},inplace=True)\n",
    "regulation_df.rename(index=str, columns={\"regulation\":\"ref\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.concat([citation_df,regulation_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times being cited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28 USC § 1295</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415 F.3d 1303</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 103</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 112</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127 S.Ct. 1727</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 L.Ed.2d 545</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167 L.Ed.2d 705</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 USC § 271</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383 U.S. 1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550 U.S. 398</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Times being cited\n",
       "ref                               \n",
       "28 USC § 1295                  119\n",
       "415 F.3d 1303                   33\n",
       "35 USC § 103                    30\n",
       "35 USC § 112                    26\n",
       "127 S.Ct. 1727                  20\n",
       "15 L.Ed.2d 545                  20\n",
       "167 L.Ed.2d 705                 20\n",
       "35 USC § 271                    20\n",
       "383 U.S. 1                      20\n",
       "550 U.S. 398                    20"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df.groupby(['ref']).count().nlargest(10, 'file').\\\n",
    "rename(index=str, columns={\"file\": \"Times being cited\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write references to `csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df.to_csv(\"reference159.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count patent frequenct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_dict = {}\n",
    "for i in range(len(pdf_name)):\n",
    "    patent_dict[pdf_name[i]] = get_patent(pdf_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.DataFrame.from_dict(patent_dict, orient='index')\n",
    "pat_df['file'] = pat_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df= pd.melt(pat_df,id_vars=['file']). \\\n",
    "     drop(['variable'], axis=1).dropna(). \\\n",
    "     rename(index=str, columns={\"value\": \"patent\"})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times being cited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1,920,033</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2,000,000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3,692,319</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5,860,973</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6,553,350</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Times being cited\n",
       "patent                      \n",
       "1,920,033                  2\n",
       "2,000,000                  2\n",
       "3,692,319                  2\n",
       "5,860,973                  2\n",
       "6,553,350                  2"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df.groupby(['patent']).count().nlargest(5, 'file').\\\n",
    "rename(index=str, columns={\"file\": \"Times being cited\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = {}\n",
    "for i in range(len(pdf_name)):\n",
    "    position_dict[pdf_name[i]] = array_position_patent(pdf_layers[i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 126), (11, 126), (11, 126), (40, 126), (40, 126), (40, 126)]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_dict[pdf_name[0]][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,188,903', '2,838,735', '6,491,070', '5,131,153', '5,261,009', '5,381,489']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_dict[pdf_name[0]][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_dict = {}\n",
    "for i in range(len(pdf_name)):\n",
    "    patent_dict[pdf_name[i]] = array_position_patent(pdf_layers[i])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_dropna = {i:j for i,j in position_dict.items() if j != []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_dict_dropna = {i:j for i,j in patent_dict.items() if j != []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patent_dict_dropna )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame.from_dict(position_dict, orient='index')\n",
    "pos_df['file'] = pos_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_df= pd.melt(pos_df,id_vars=['file']). \\\n",
    "     drop(['variable'], axis=1).dropna(). \\\n",
    "     rename(index=str, columns={\"value\": \"position\"})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(11, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(11, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(11, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(40, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(40, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>(40, 126)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file   position\n",
       "0    052 - Nuance Communications Inc v ABBYY USA So...  (11, 126)\n",
       "159  052 - Nuance Communications Inc v ABBYY USA So...  (11, 126)\n",
       "318  052 - Nuance Communications Inc v ABBYY USA So...  (11, 126)\n",
       "477  052 - Nuance Communications Inc v ABBYY USA So...  (40, 126)\n",
       "636  052 - Nuance Communications Inc v ABBYY USA So...  (40, 126)\n",
       "795  052 - Nuance Communications Inc v ABBYY USA So...  (40, 126)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_df.loc[position_df.file == pdf_name[0]][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.DataFrame.from_dict(patent_dict, orient='index')\n",
    "pat_df['file'] = pat_df.index\n",
    "patent_df= pd.melt(pat_df,id_vars=['file']). \\\n",
    "     drop(['variable'], axis=1).dropna(). \\\n",
    "     rename(index=str, columns={\"value\": \"patent\"})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>patent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>1,188,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>2,838,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>6,491,070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>5,131,153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>5,261,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>5,381,489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file     patent\n",
       "0    052 - Nuance Communications Inc v ABBYY USA So...  1,188,903\n",
       "159  052 - Nuance Communications Inc v ABBYY USA So...  2,838,735\n",
       "318  052 - Nuance Communications Inc v ABBYY USA So...  6,491,070\n",
       "477  052 - Nuance Communications Inc v ABBYY USA So...  5,131,153\n",
       "636  052 - Nuance Communications Inc v ABBYY USA So...  5,261,009\n",
       "795  052 - Nuance Communications Inc v ABBYY USA So...  5,381,489"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df.loc[patent_df.file == pdf_name[0]][0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df =patent_df.assign(position = position_df['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>patent</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>052 - Nuance Communications Inc v ABBYY USA So...</td>\n",
       "      <td>1,188,903</td>\n",
       "      <td>(11, 126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>021 - Intellectual Ventures I LLC v Erie Indem...</td>\n",
       "      <td>6,236,983</td>\n",
       "      <td>(134, 296)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>021 - Aspex Eyewear Inc v Zenni Optical Inc</td>\n",
       "      <td>5,737,054</td>\n",
       "      <td>(38, 104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>056 - Soverain Software LLC v Newegg Inc</td>\n",
       "      <td>5,715,314</td>\n",
       "      <td>(23, 83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100 - In re Geller</td>\n",
       "      <td>2,365,001</td>\n",
       "      <td>(8, 109)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file     patent    position\n",
       "0  052 - Nuance Communications Inc v ABBYY USA So...  1,188,903   (11, 126)\n",
       "1  021 - Intellectual Ventures I LLC v Erie Indem...  6,236,983  (134, 296)\n",
       "3        021 - Aspex Eyewear Inc v Zenni Optical Inc  5,737,054   (38, 104)\n",
       "4           056 - Soverain Software LLC v Newegg Inc  5,715,314    (23, 83)\n",
       "5                                 100 - In re Geller  2,365,001    (8, 109)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write extracted dates to `csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = []\n",
    "for text in pdf_text:\n",
    "    try:\n",
    "        date_list.append(get_date(text))\n",
    "    except:\n",
    "        date_list.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if extract the date for every pdf\n",
    "for i in range(len(date_list)):\n",
    "    if date_list[i] == None:\n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(\n",
    "    {'file_name': pdf_name,\n",
    "     'dates':date_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0dfcbe4bebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metadata159.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "metadata.to_csv(\"metadata159.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
